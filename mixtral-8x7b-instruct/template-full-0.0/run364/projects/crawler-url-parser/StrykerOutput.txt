*** using precomputed mutations ***
[32m15:41:39 (2553) INFO ConfigReader[39m No config file specified. Running with command line arguments.
[32m15:41:39 (2553) INFO ConfigReader[39m Use `stryker init` command to generate your config file.
[33m15:41:39 (2553) WARN PluginLoader[39m Error during loading "@stryker-mutator/karma-runner" plugin:
  Cannot find module 'karma'
Require stack:
- /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/util/dist/src/require-resolve.js
[33m15:41:39 (2553) WARN OptionsValidator[39m Unknown stryker config option "usePrecomputed".
[33m15:41:39 (2553) WARN OptionsValidator[39m Possible causes:
     * Is it a typo on your end?
     * Did you only write this property as a comment? If so, please postfix it with "_comment".
     * You might be missing a plugin that is supposed to use it. Stryker loaded plugins from: ["@stryker-mutator/*"]
     * The plugin that is using it did not contribute explicit validation. 
     (disable "warnings.unknownOptions" to ignore this warning)
[32m15:41:40 (2553) INFO ProjectReader[39m Found 1 of 741 file(s) to be mutated.
*** using precomputed mutator ***
*** retrieving 225 mutants from MUTATION_TESTING/template-full_mixtral-8x7b-instruct_0.0/mutants.json ***
Mutant 0 in crawler-url-parser.js: str replaced with 'str'.toLowerCase()
Mutant 1 in crawler-url-parser.js: str replaced with document.location.href
Mutant 2 in crawler-url-parser.js: typeof currentUrlStr === 'undefined' replaced with currentUrlStr === null
Mutant 3 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr !== null && _has_illegal_chars(currentUrlStr)
Mutant 4 in crawler-url-parser.js: _has_illegal_chars replaced with currentUrlStr.length > 100
Mutant 5 in crawler-url-parser.js: _has_illegal_chars replaced with typeof currentUrlStr !== 'string'
Mutant 6 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.toString()
Mutant 7 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr || ''
Mutant 8 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr ?? ''
Mutant 9 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with typeof baseUrlStr !== 'undefined' && _has_illegal_chars(baseUrlStr)
Mutant 10 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with baseUrlStr && _has_illegal_chars(baseUrlStr.toString())
Mutant 11 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with _has_illegal_chars(baseUrlStr || '')
Mutant 12 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 13 in crawler-url-parser.js: baseUrlStr replaced with "baseUrlStr"
Mutant 14 in crawler-url-parser.js: baseUrlStr replaced with baseUrlStr.toUpperCase()
Mutant 15 in crawler-url-parser.js: /#.*$/ replaced with /[#].*$/
Mutant 16 in crawler-url-parser.js: /#.*$/ replaced with /#.+$/
Mutant 17 in crawler-url-parser.js: '' replaced with '#' + Math.random()
Mutant 18 in crawler-url-parser.js: '' replaced with '#some-fragment'
Mutant 19 in crawler-url-parser.js: '' replaced with '?foo=bar'
Mutant 20 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 21 in crawler-url-parser.js: baseUrlStr replaced with null
failed to parse replacement '^[/][/]': SyntaxError: Invalid regular expression: //][//: Unterminated character class
Mutant 22 in crawler-url-parser.js: /^\/\// replaced with '^\\/\\/'
Mutant 23 in crawler-url-parser.js: 'http://' replaced with ' '
Mutant 24 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*/, '')
Mutant 25 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/[?].*$/, '')
Mutant 26 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*$/, '!')
Mutant 27 in crawler-url-parser.js: /#.*$/ replaced with /[#].*$/
Mutant 28 in crawler-url-parser.js: /#.*$/ replaced with /;.*$/
Mutant 29 in crawler-url-parser.js: /#.*$/ replaced with /&.*$/
Mutant 30 in crawler-url-parser.js: '' replaced with baseUrlStr.slice(0, -1)
Mutant 31 in crawler-url-parser.js: '' replaced with '?'
Mutant 32 in crawler-url-parser.js: '' replaced with Math.random()
Mutant 33 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with currentUrlStr.startsWith('http')
Mutant 34 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with /^[a-z0-9]+:/.test(currentUrlStr)
failed to parse replacement /^(?!(?:[a-z0-9]+:)?\/\/)/i: SyntaxError: Invalid regular expression: //^(?!(?:[a-z0-9]+:)?\//: Unterminated group
failed to parse replacement /^(?!(?:\w+):?\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:\w+):?\//: Unterminated group
failed to parse replacement /^(?!(?:https?|ftp):?\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:https?|ftp):?\//: Unterminated group
Mutant 35 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 36 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 37 in crawler-url-parser.js: true replaced with false
Mutant 38 in crawler-url-parser.js: true replaced with false
Mutant 39 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true)
Mutant 40 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true, false)
Mutant 41 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with parsedUrl.protocol !== 'http:' && parsedUrl.protocol !== 'https:'
Mutant 42 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with parsedUrl.host === null && baseUrlStr
Mutant 43 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse('', true, true)
Mutant 44 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, false, true)
Mutant 45 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, true, false)
Mutant 46 in crawler-url-parser.js: baseUrlStr replaced with baseUrl.url
Mutant 47 in crawler-url-parser.js: baseUrlStr replaced with Math.random().toString()
Mutant 48 in crawler-url-parser.js: true replaced with false
Mutant 49 in crawler-url-parser.js: true replaced with false
Mutant 50 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, true, false)
Mutant 51 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, false, true)
Mutant 52 in crawler-url-parser.js: parsedBaseUrl replaced with parsedBaseUrl.toString()
Mutant 53 in crawler-url-parser.js: parsedBaseUrl replaced with URL.format({
  ...parsedBaseUrl
})
Mutant 54 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve({})
Mutant 55 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(null)
Mutant 56 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(URL.parse(''))
Mutant 57 in crawler-url-parser.js: URL.resolve replaced with parsedBaseUrl.origin + parsedUrl.path
Mutant 58 in crawler-url-parser.js: parsedBaseUrl replaced with {}
Mutant 59 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse('')
Mutant 60 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse(currentUrlStr)
Mutant 61 in crawler-url-parser.js: parsedUrl replaced with '..'
Mutant 62 in crawler-url-parser.js: parsedUrl replaced with './'
Mutant 63 in crawler-url-parser.js: parsedUrl replaced with '/./'
Mutant 64 in crawler-url-parser.js: URL.format replaced with null
Mutant 65 in crawler-url-parser.js: absoluteUrl replaced with parsedUrl.href
Mutant 66 in crawler-url-parser.js: absoluteUrl replaced with URL.format(absoluteUrl, result_normalize_options)
Mutant 67 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 68 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 69 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.toUpperCase()
Mutant 70 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.slice(0, -1)
Mutant 71 in crawler-url-parser.js: true replaced with false
Mutant 72 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, result_normalize_options, true)
Mutant 73 in crawler-url-parser.js: true replaced with false
Mutant 74 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true, false)
Mutant 75 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, false, true)
Mutant 76 in crawler-url-parser.js: URL.format replaced with parsedUrl.href
Mutant 77 in crawler-url-parser.js: parsedUrl replaced with Object.assign({}, parsedUrl)
Mutant 78 in crawler-url-parser.js: ret.host replaced with false
Mutant 79 in crawler-url-parser.js: ret.host replaced with null
Mutant 80 in crawler-url-parser.js: ret.host replaced with psl.parse('example.com')
Mutant 81 in crawler-url-parser.js: ret.host replaced with null
Mutant 82 in crawler-url-parser.js: "=" replaced with '=='
Mutant 83 in crawler-url-parser.js: "=" replaced with '!=='
Mutant 84 in crawler-url-parser.js: parse replaced with 'parse'
Mutant 85 in crawler-url-parser.js: sourceUrl replaced with null
Mutant 86 in crawler-url-parser.js: data replaced with cheerio.load('<html><body><a href="test"></a></body></html>')
Mutant 87 in crawler-url-parser.js: 'base' replaced with $('script')[0].attribs['src']
Mutant 88 in crawler-url-parser.js: 'base' replaced with $('a').eq(0).attr('href')
Mutant 89 in crawler-url-parser.js: 'base' replaced with $('a').find('href')
Mutant 90 in crawler-url-parser.js: 'href' replaced with $('base').attr('data-href')
Mutant 91 in crawler-url-parser.js: 'href' replaced with $('head base').attr('href')
Mutant 92 in crawler-url-parser.js: 'href' replaced with $(el).attr('href')
Mutant 93 in crawler-url-parser.js: embedBaseUrlStr replaced with 'javascript:void(0)'
Mutant 94 in crawler-url-parser.js: embedBaseUrlStr replaced with true
Mutant 95 in crawler-url-parser.js: embedBaseUrlStr replaced with $('body').html()
Mutant 96 in crawler-url-parser.js: 'a' replaced with '$("body a")'
Mutant 97 in crawler-url-parser.js: 'a' replaced with '$("a")[0]'
Mutant 98 in crawler-url-parser.js: 'a' replaced with 'document.querySelectorAll("a")'
Mutant 99 in crawler-url-parser.js: this replaced with $('body')
Mutant 100 in crawler-url-parser.js: this replaced with null
Mutant 101 in crawler-url-parser.js: this replaced with document.createElement('a')
Mutant 102 in crawler-url-parser.js: 'href' replaced with 'href' in el && el['href']
Mutant 103 in crawler-url-parser.js: 'href' replaced with $(el).attr('data-href')
Mutant 104 in crawler-url-parser.js: 'href' replaced with el.getAttribute('href')
Mutant 105 in crawler-url-parser.js: this replaced with $('body')
Mutant 106 in crawler-url-parser.js: this replaced with $(this).parent()
Mutant 107 in crawler-url-parser.js: this replaced with 'some text'
Mutant 108 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with href === null || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)
Mutant 109 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with typeof href === "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/i.test(href)
Mutant 110 in crawler-url-parser.js: href replaced with ''.concat(href)
Mutant 111 in crawler-url-parser.js: href replaced with href || ''
Mutant 112 in crawler-url-parser.js: href replaced with (href || '').replace(/;.*$/g, "")
Mutant 113 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse({
  href: baseUrlStr
})
Mutant 114 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(parse('some_random_string'))
Mutant 115 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(href || baseUrlStr)
Mutant 116 in crawler-url-parser.js: parse replaced with 'bad_parse'
Mutant 117 in crawler-url-parser.js: href replaced with './'
Mutant 118 in crawler-url-parser.js: href replaced with null
Mutant 119 in crawler-url-parser.js: href replaced with 'javascript:alert("XSS")'
Mutant 120 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 121 in crawler-url-parser.js: baseUrlStr replaced with "some_string"
Mutant 122 in crawler-url-parser.js: baseUrlStr replaced with () => "some_string"
Mutant 123 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl !== null && currentUrl.url
Mutant 124 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl && currentUrl['url']
Mutant 125 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.toString()
Mutant 126 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 127 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.__proto__.url
Mutant 128 in crawler-url-parser.js: urlMap.get replaced with urlMap.has
Mutant 129 in crawler-url-parser.js: urlMap.get replaced with urlMap.prototype.get
Mutant 130 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 131 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text === text
Mutant 132 in crawler-url-parser.js: text replaced with ''
Mutant 133 in crawler-url-parser.js: text replaced with null
Mutant 134 in crawler-url-parser.js: text replaced with $(this).attr('title')
Mutant 135 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set('currentUrl.url, "currentUrl"')
Mutant 136 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(`currentUrl.url, ${currentUrl}`)
Mutant 137 in crawler-url-parser.js: urlMap.set replaced with urlMap.has
Mutant 138 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.toString()
Mutant 139 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 140 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.__proto__.url
Mutant 141 in crawler-url-parser.js: currentUrl replaced with null
Mutant 142 in crawler-url-parser.js: currentUrl replaced with {}
Mutant 143 in crawler-url-parser.js: currentUrl replaced with function () {
  return {
    url: currentUrl.url,
    text: text,
    type: 'unknown'
  };
}()
Mutant 144 in crawler-url-parser.js: baseUrlStr replaced with null
Mutant 145 in crawler-url-parser.js: urlMap.values() replaced with [...urlMap.values()]
Mutant 146 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(null)
Mutant 147 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype({})
Mutant 148 in crawler-url-parser.js: currentUrl replaced with null
Mutant 149 in crawler-url-parser.js: currentUrl replaced with {}
Mutant 150 in crawler-url-parser.js: baseUrl replaced with false
Mutant 151 in crawler-url-parser.js: baseUrl replaced with null
Mutant 152 in crawler-url-parser.js: urlMap.values() replaced with [...urlMap.values()]
Mutant 153 in crawler-url-parser.js: urlMap.values() replaced with Array.from(urlMap.keys())
Mutant 154 in crawler-url-parser.js: urlMap.values() replaced with Object.values(urlMap)
Mutant 155 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl instanceof URL
Mutant 156 in crawler-url-parser.js: linkurl replaced with {}
Mutant 157 in crawler-url-parser.js: linkurl replaced with null
Mutant 158 in crawler-url-parser.js: linkurl replaced with Math.random()
Mutant 159 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl instanceof URL
Mutant 160 in crawler-url-parser.js: parse replaced with {}
Mutant 161 in crawler-url-parser.js: parse replaced with ['parse']
Mutant 162 in crawler-url-parser.js: pageurl replaced with {}
Mutant 163 in crawler-url-parser.js: pageurl replaced with global.pageurl
Mutant 164 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\..+$/, '/')
Mutant 165 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\.[a-z]+$/i, '/')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\..+$/, '/')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\.[a-z]+$/i, '/')
Mutant 166 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\..+$/
Mutant 167 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[A-Z]+$/
Mutant 168 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-zA-Z]+$/
Mutant 169 in crawler-url-parser.js: '/' replaced with './'
Mutant 170 in crawler-url-parser.js: '/' replaced with ' '
Mutant 171 in crawler-url-parser.js: '/' replaced with ''
Mutant 172 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace('')
Mutant 173 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\..+$/, '/')
not replacing pageurl_path.replace(/\/index\.[a-z]+$/, '/') with pageurl_path.replace(/\/index\..+$/, '/')
Mutant 174 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with '/index\\.[a-z]+$'
Mutant 175 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.\w+$/
Mutant 176 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+\/*$/
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "X"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "") + 'Y': SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 177 in crawler-url-parser.js: '/' replaced with pageurl_path.slice(0, -1)
Mutant 178 in crawler-url-parser.js: "/" replaced with "/."
Mutant 179 in crawler-url-parser.js: pageurl_path.split replaced with pageurl.path.split
not replacing pageurl_path.split with pageurl.path.split
not replacing pageurl_path.split with pageurl.path.split
Mutant 180 in crawler-url-parser.js: "/" replaced with ""
Mutant 181 in crawler-url-parser.js: "/" replaced with new RegExp('/')
Mutant 182 in crawler-url-parser.js: "/" replaced with "/".concat(String.fromCharCode(0))
Mutant 183 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with pageurl.host === linkurl.host
Mutant 184 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with pageurl.hostname == linkurl.host
Mutant 185 in crawler-url-parser.js: part_count_diff == 0 replaced with linkurl_path === pageurl_path
failed to parse replacement linkurl_path.replace(/[^\/]*$/, ""): SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement linkurl_path.replace(/(\/[^\/]+)\/?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement linkurl_path.replace(/(\/[^\/]*)?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /[^\/]*$/: SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement /[^\/]+$/: SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
Mutant 186 in crawler-url-parser.js: /(\/[^\/]*)[\/]?$/ replaced with /.*$/
failed to parse replacement pageurl_path.replace(/[^\/]*$/, ""): SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 187 in crawler-url-parser.js: "" replaced with pageurl_path
Mutant 188 in crawler-url-parser.js: "" replaced with pageurl_path + "/"
Mutant 189 in crawler-url-parser.js: "" replaced with pageurl_path.slice(0, -1)
Mutant 190 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part === pageurl_without_last_part
Mutant 191 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part.localeCompare(pageurl_without_last_part) === 0
Mutant 192 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff > 0
Mutant 193 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with pageurl_path.startsWith(linkurl_path)
Mutant 194 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff === -2
Mutant 195 in crawler-url-parser.js: part_count_diff == -1 replaced with pageurl_path.startsWith(linkurl_path)
Mutant 196 in crawler-url-parser.js: part_count_diff == -1 replaced with linkurl_subdomain_len > pageurl_subdomain_len
Mutant 197 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.startsWith(pageurl_path)
Mutant 198 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with pageurl_path.indexOf(linkurl_path) !== -1
Mutant 199 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain === pageurl.domain
Mutant 200 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.hasOwnProperty('domain') && linkurl.domain == pageurl.domain
Mutant 201 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain.toLowerCase() == pageurl.domain.toLowerCase()
Mutant 202 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl.subdomain.length < pageurl.subdomain.length
Mutant 203 in crawler-url-parser.js: !module.parent replaced with typeof module.parent === 'undefined'
Mutant 204 in crawler-url-parser.js: !module.parent replaced with !module.exports
Mutant 205 in crawler-url-parser.js: console.log replaced with console.error
Mutant 206 in crawler-url-parser.js: console.log replaced with alert
Mutant 207 in crawler-url-parser.js: "for testing purpose" replaced with "use testing purpose"
Mutant 208 in crawler-url-parser.js: "for testing purpose" replaced with "if (!module.parent) { console.log('Testing purpose');"
Mutant 209 in crawler-url-parser.js: "for testing purpose" replaced with "if (!module.parent) { console.log('Testing purposes');"
Mutant 210 in crawler-url-parser.js: url replaced with url.toUpperCase()
Mutant 211 in crawler-url-parser.js: url replaced with null
[32m15:41:40 (2553) INFO Instrumenter[39m Instrumented 1 source file(s) with 212 mutant(s)
[33m15:41:40 (2553) WARN DisableTypeChecksPreprocessor[39m Unable to disable type checking for file "/home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html". Shouldn't type checking be disabled for this file? Consider configuring a more restrictive "disableTypeChecks" settings (or turn it completely off with `false`) ParseError: Parse error in /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html (73:43) Opening tag "a" not terminated.
    at ngHtmlParser (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:28:15)
    at async parse (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:11:18)
    at async DisableTypeChecksPreprocessor.disableTypeChecks [as impl] (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/disable-type-checks.js:28:17)
    at async file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:27:41
    at async Promise.all (index 736)
    at async DisableTypeChecksPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:24:9)
    at async MultiPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/multi-preprocessor.js:8:13)
    at async MutantInstrumenterExecutor.execute (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/process/2-mutant-instrumenter-executor.js:30:9)
    at async Stryker.runMutationTest (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/stryker.js:33:48)
[33m15:41:40 (2553) WARN DisableTypeChecksPreprocessor[39m (disable "warnings.preprocessorErrors" to ignore this warning
[32m15:41:40 (2553) INFO ConcurrencyTokenProvider[39m Creating 1 test runner process(es).
[32m15:41:41 (2553) INFO BroadcastReporter[39m Detected that current console does not support the "progress" reporter, downgrading to "progress-append-only" reporter
[32m15:41:41 (2553) INFO DryRunExecutor[39m Starting initial test run (command test runner with "perTest" coverage analysis). This may take a while.
[32m15:41:46 (2553) INFO DryRunExecutor[39m Initial test run succeeded. Ran 1 tests in 5 seconds (net 5427 ms, overhead 2 ms).
Mutation testing 1% (elapsed: <1m, remaining: ~11m) 3/212 tested (0 survived, 0 timed out)
Mutation testing 2% (elapsed: <1m, remaining: ~11m) 6/212 tested (1 survived, 0 timed out)
Mutation testing 4% (elapsed: <1m, remaining: ~11m) 9/212 tested (4 survived, 0 timed out)
Mutation testing 5% (elapsed: <1m, remaining: ~11m) 12/212 tested (7 survived, 0 timed out)
Mutation testing 7% (elapsed: <1m, remaining: ~10m) 15/212 tested (8 survived, 0 timed out)
Mutation testing 8% (elapsed: ~1m, remaining: ~10m) 18/212 tested (11 survived, 0 timed out)
Mutation testing 9% (elapsed: ~1m, remaining: ~10m) 21/212 tested (12 survived, 0 timed out)
Mutation testing 11% (elapsed: ~1m, remaining: ~10m) 24/212 tested (12 survived, 0 timed out)
Mutation testing 12% (elapsed: ~1m, remaining: ~10m) 27/212 tested (15 survived, 0 timed out)
Mutation testing 14% (elapsed: ~1m, remaining: ~10m) 30/212 tested (18 survived, 0 timed out)
Mutation testing 15% (elapsed: ~1m, remaining: ~9m) 33/212 tested (21 survived, 0 timed out)
Mutation testing 16% (elapsed: ~2m, remaining: ~9m) 36/212 tested (22 survived, 0 timed out)
Mutation testing 18% (elapsed: ~2m, remaining: ~9m) 39/212 tested (25 survived, 0 timed out)
Mutation testing 19% (elapsed: ~2m, remaining: ~9m) 42/212 tested (27 survived, 0 timed out)
Mutation testing 21% (elapsed: ~2m, remaining: ~9m) 45/212 tested (29 survived, 0 timed out)
Mutation testing 22% (elapsed: ~2m, remaining: ~9m) 48/212 tested (30 survived, 0 timed out)
Mutation testing 24% (elapsed: ~2m, remaining: ~8m) 51/212 tested (33 survived, 0 timed out)
Mutation testing 25% (elapsed: ~3m, remaining: ~8m) 54/212 tested (35 survived, 0 timed out)
Mutation testing 27% (elapsed: ~3m, remaining: ~8m) 58/212 tested (35 survived, 0 timed out)
Mutation testing 28% (elapsed: ~3m, remaining: ~8m) 61/212 tested (35 survived, 0 timed out)
Mutation testing 30% (elapsed: ~3m, remaining: ~8m) 64/212 tested (35 survived, 0 timed out)
Mutation testing 31% (elapsed: ~3m, remaining: ~7m) 67/212 tested (36 survived, 0 timed out)
Mutation testing 33% (elapsed: ~3m, remaining: ~7m) 70/212 tested (38 survived, 0 timed out)
Mutation testing 34% (elapsed: ~4m, remaining: ~7m) 73/212 tested (40 survived, 0 timed out)
Mutation testing 35% (elapsed: ~4m, remaining: ~7m) 76/212 tested (43 survived, 0 timed out)
Mutation testing 37% (elapsed: ~4m, remaining: ~7m) 79/212 tested (44 survived, 0 timed out)
Mutation testing 39% (elapsed: ~4m, remaining: ~6m) 83/212 tested (44 survived, 0 timed out)
Mutation testing 40% (elapsed: ~4m, remaining: ~6m) 86/212 tested (44 survived, 0 timed out)
Mutation testing 41% (elapsed: ~4m, remaining: ~6m) 89/212 tested (44 survived, 0 timed out)
Mutation testing 43% (elapsed: ~5m, remaining: ~6m) 93/212 tested (44 survived, 0 timed out)
Mutation testing 45% (elapsed: ~5m, remaining: ~6m) 96/212 tested (44 survived, 0 timed out)
Mutation testing 46% (elapsed: ~5m, remaining: ~6m) 99/212 tested (44 survived, 0 timed out)
Mutation testing 48% (elapsed: ~5m, remaining: ~5m) 103/212 tested (44 survived, 0 timed out)
Mutation testing 50% (elapsed: ~5m, remaining: ~5m) 106/212 tested (45 survived, 0 timed out)
Mutation testing 50% (elapsed: ~5m, remaining: ~5m) 108/212 tested (47 survived, 0 timed out)
Mutation testing 52% (elapsed: ~6m, remaining: ~5m) 111/212 tested (50 survived, 0 timed out)
Mutation testing 54% (elapsed: ~6m, remaining: ~5m) 115/212 tested (52 survived, 0 timed out)
Mutation testing 55% (elapsed: ~6m, remaining: ~5m) 118/212 tested (52 survived, 0 timed out)
Mutation testing 57% (elapsed: ~6m, remaining: ~4m) 122/212 tested (52 survived, 0 timed out)
Mutation testing 58% (elapsed: ~6m, remaining: ~4m) 125/212 tested (54 survived, 0 timed out)
Mutation testing 60% (elapsed: ~6m, remaining: ~4m) 128/212 tested (57 survived, 0 timed out)
Mutation testing 61% (elapsed: ~7m, remaining: ~4m) 131/212 tested (58 survived, 0 timed out)
Mutation testing 63% (elapsed: ~7m, remaining: ~4m) 134/212 tested (61 survived, 0 timed out)
Mutation testing 64% (elapsed: ~7m, remaining: ~4m) 137/212 tested (62 survived, 0 timed out)
Mutation testing 66% (elapsed: ~7m, remaining: ~3m) 140/212 tested (63 survived, 0 timed out)
Mutation testing 67% (elapsed: ~7m, remaining: ~3m) 143/212 tested (63 survived, 0 timed out)
Mutation testing 68% (elapsed: ~7m, remaining: ~3m) 146/212 tested (65 survived, 0 timed out)
Mutation testing 70% (elapsed: ~8m, remaining: ~3m) 149/212 tested (65 survived, 0 timed out)
Mutation testing 71% (elapsed: ~8m, remaining: ~3m) 152/212 tested (65 survived, 0 timed out)
Mutation testing 73% (elapsed: ~8m, remaining: ~3m) 155/212 tested (66 survived, 0 timed out)
Mutation testing 74% (elapsed: ~8m, remaining: ~2m) 158/212 tested (66 survived, 0 timed out)
Mutation testing 75% (elapsed: ~8m, remaining: ~2m) 160/212 tested (66 survived, 0 timed out)
Mutation testing 76% (elapsed: ~8m, remaining: ~2m) 163/212 tested (66 survived, 0 timed out)
Mutation testing 78% (elapsed: ~9m, remaining: ~2m) 166/212 tested (68 survived, 0 timed out)
Mutation testing 79% (elapsed: ~9m, remaining: ~2m) 169/212 tested (70 survived, 0 timed out)
Mutation testing 81% (elapsed: ~9m, remaining: ~2m) 172/212 tested (71 survived, 0 timed out)
Mutation testing 82% (elapsed: ~9m, remaining: ~2m) 175/212 tested (73 survived, 0 timed out)
Mutation testing 83% (elapsed: ~9m, remaining: ~1m) 178/212 tested (76 survived, 0 timed out)
Mutation testing 85% (elapsed: ~9m, remaining: ~1m) 181/212 tested (77 survived, 0 timed out)
Mutation testing 86% (elapsed: ~10m, remaining: ~1m) 184/212 tested (79 survived, 0 timed out)
Mutation testing 88% (elapsed: ~10m, remaining: ~1m) 187/212 tested (79 survived, 0 timed out)
Mutation testing 89% (elapsed: ~10m, remaining: ~1m) 190/212 tested (79 survived, 0 timed out)
Mutation testing 90% (elapsed: ~10m, remaining: ~1m) 192/212 tested (81 survived, 0 timed out)
Mutation testing 91% (elapsed: ~10m, remaining: <1m) 195/212 tested (81 survived, 0 timed out)
Mutation testing 93% (elapsed: ~10m, remaining: <1m) 198/212 tested (82 survived, 0 timed out)
Mutation testing 94% (elapsed: ~11m, remaining: <1m) 201/212 tested (85 survived, 0 timed out)
Mutation testing 96% (elapsed: ~11m, remaining: <1m) 204/212 tested (87 survived, 0 timed out)
Mutation testing 97% (elapsed: ~11m, remaining: <1m) 207/212 tested (90 survived, 0 timed out)
Mutation testing 99% (elapsed: ~11m, remaining: <1m) 210/212 tested (93 survived, 0 timed out)

All tests
  âœ“ All tests (killed 117)

[Survived] PrecomputedMutator
crawler-url-parser.js:32:6
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr !== null && _has_illegal_chars(currentUrlStr)) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr.toString())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr || '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr ?? '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (typeof baseUrlStr !== 'undefined' && _has_illegal_chars(baseUrlStr)) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (baseUrlStr && _has_illegal_chars(baseUrlStr.toString())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (_has_illegal_chars(baseUrlStr || '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:39
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (baseUrlStr && _has_illegal_chars(baseUrlStr.toUpperCase())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/[#].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.+$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#' + Math.random());

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#some-fragment');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/[?].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '!');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/[#].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/;.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/&.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, baseUrlStr.slice(0, -1));

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '?');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, Math.random());

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:43
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true, false));

[Survived] PrecomputedMutator
crawler-url-parser.js:54:6
-   	if (parsedUrl.host == null && baseUrlStr) {
+   	if (parsedUrl.host === null && baseUrlStr) {

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, URL.parse(baseUrlStr, true, false));

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, URL.parse(baseUrlStr, false, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:57:28
-   		ret.baseurl = URL.format(parsedBaseUrl);
+   		ret.baseurl = URL.format(URL.format({
+     ...parsedBaseUrl
+   }));

[Survived] PrecomputedMutator
crawler-url-parser.js:60:30
-   		currentUrlStr = URL.format(absoluteUrl);
+   		currentUrlStr = URL.format(URL.format(absoluteUrl, result_normalize_options));

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, URL.parse(currentUrlStr, result_normalize_options, true), true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true, false));

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, false, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:66:23
-   	ret.url = URL.format(parsedUrl);
+   	ret.url = URL.format(Object.assign({}, parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($('body')).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($(this).parent()).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $('some text').text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (href === null || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href === "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/i.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(''.concat(href))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href || '')) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test((href || '').replace(/;.*$/g, ""))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl !== null && currentUrl.url) {

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl && currentUrl['url']) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.toString())) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl['url'])) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.__proto__.url)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:103:29
-   				let tmpUrl = urlMap.get(currentUrl.url);
+   				let tmpUrl = urlMap.get(currentUrl['url']);

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text === text) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes('')) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes(null)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes($(this).attr('title'))) {

[Survived] PrecomputedMutator
crawler-url-parser.js:110:16
-   				urlMap.set(currentUrl.url, currentUrl);
+   				urlMap.set(currentUrl['url'], currentUrl);

[Survived] PrecomputedMutator
crawler-url-parser.js:116:16
-   	urlMap.delete(baseUrlStr);
+   	urlMap.delete(null);

[Survived] PrecomputedMutator
crawler-url-parser.js:118:25
-   	for (let currentUrl of urlMap.values()) {
+   	for (let currentUrl of [...urlMap.values()]) {

[Survived] PrecomputedMutator
crawler-url-parser.js:122:26
-   	let retArr = Array.from(urlMap.values());
+   	let retArr = Array.from([...urlMap.values()]);

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/i, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-zA-Z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:58
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:17
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace('/index\\.[a-z]+$', '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.\w+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+\/*$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:93
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, pageurl_path.slice(0, -1));

[Survived] PrecomputedMutator
crawler-url-parser.js:152:22
-   	let pageurl_parts = pageurl_path.split("/").filter(function (elem, index, array) {
+   	let pageurl_parts = pageurl.path.split("/").filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:152:41
-   	let pageurl_parts = pageurl_path.split("/").filter(function (elem, index, array) {
+   	let pageurl_parts = pageurl_path.split(new RegExp('/')).filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:156:6
-   	if (pageurl.host == linkurl.host) {
+   	if (pageurl.host === linkurl.host) {

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part === pageurl_without_last_part) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part.localeCompare(pageurl_without_last_part) === 0) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:166:14
-   		} else if (part_count_diff == -1) {
+   		} else if (pageurl_path.startsWith(linkurl_path)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:167:8
-   			if (pageurl_path.includes(linkurl_path)) return "uplevel";
+   			if (pageurl_path.indexOf(linkurl_path) !== -1) return "uplevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain === pageurl.domain) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.hasOwnProperty('domain') && linkurl.domain == pageurl.domain) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain.toLowerCase() == pageurl.domain.toLowerCase()) {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (typeof module.parent === 'undefined') {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (!module.exports) {

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	console.error("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	alert("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("use testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("if (!module.parent) { console.log('Testing purpose');");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("if (!module.parent) { console.log('Testing purposes');");

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(url.toUpperCase());

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(null);

Ran 1.00 tests per mutant on average.
-----------------------|---------|----------|-----------|------------|----------|----------|
File                   | % score | # killed | # timeout | # survived | # no cov | # errors |
-----------------------|---------|----------|-----------|------------|----------|----------|
All files              |   55.19 |      117 |         0 |         95 |        0 |        0 |
 crawler-url-parser.js |   55.19 |      117 |         0 |         95 |        0 |        0 |
-----------------------|---------|----------|-----------|------------|----------|----------|
[32m15:53:23 (2553) INFO HtmlReporter[39m Your report can be found at: file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/reports/mutation/mutation.html
[32m15:53:23 (2553) INFO MutationTestExecutor[39m Done in 11 minutes 43 seconds.

real	11m45.157s
user	8m51.175s
sys	0m42.236s
