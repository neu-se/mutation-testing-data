*** using precomputed mutations ***
[32m06:17:51 (2494) INFO ConfigReader[39m No config file specified. Running with command line arguments.
[32m06:17:51 (2494) INFO ConfigReader[39m Use `stryker init` command to generate your config file.
[33m06:17:52 (2494) WARN PluginLoader[39m Error during loading "@stryker-mutator/karma-runner" plugin:
  Cannot find module 'karma'
Require stack:
- /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/util/dist/src/require-resolve.js
[33m06:17:52 (2494) WARN OptionsValidator[39m Unknown stryker config option "usePrecomputed".
[33m06:17:52 (2494) WARN OptionsValidator[39m Possible causes:
     * Is it a typo on your end?
     * Did you only write this property as a comment? If so, please postfix it with "_comment".
     * You might be missing a plugin that is supposed to use it. Stryker loaded plugins from: ["@stryker-mutator/*"]
     * The plugin that is using it did not contribute explicit validation. 
     (disable "warnings.unknownOptions" to ignore this warning)
[32m06:17:52 (2494) INFO ProjectReader[39m Found 1 of 741 file(s) to be mutated.
*** using precomputed mutator ***
*** retrieving 264 mutants from MUTATION_TESTING/template-noinstructions_codellama-34b-instruct_0.0/mutants.json ***
failed to parse replacement str.replace(/[^a-z0-9\:\/\?\#\[\]\@\!\$\&\'\(\)\*\+\,\;\=\.\-\_\~\%]/i, ''): SyntaxError: Invalid regular expression: //[^a-z0-9\:\//: Unterminated character class
failed to parse replacement str.replace(/[^a-z0-9\:\/\?\#\[\]\@\!\$\&\'\(\)\*\+\,\;\=\.\-\_\~\%]/i, ' '): SyntaxError: Invalid regular expression: //[^a-z0-9\:\//: Unterminated character class
Mutant 0 in crawler-url-parser.js: typeof currentUrlStr === 'undefined' replaced with currentUrlStr === undefined
Mutant 1 in crawler-url-parser.js: typeof currentUrlStr === 'undefined' replaced with currentUrlStr == null
Mutant 2 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr && !_has_illegal_chars(currentUrlStr)
Mutant 3 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr && _has_illegal_chars(currentUrlStr) && false
Mutant 4 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr && _has_illegal_chars(currentUrlStr) && true
failed to parse replacement baseUrlStr.replace(/^(?!(?:\w+:)?\/\/)/, ''): SyntaxError: Invalid regular expression: //^(?!(?:\w+:)?\//: Unterminated group
Mutant 5 in crawler-url-parser.js: currentUrlStr.replace(/#.*$/, '') replaced with currentUrlStr.replace(/#.*$/, ' ')
Mutant 6 in crawler-url-parser.js: currentUrlStr.replace(/#.*$/, '') replaced with currentUrlStr.replace(/#.*$/, '?')
Mutant 7 in crawler-url-parser.js: currentUrlStr.replace(/#.*$/, '') replaced with currentUrlStr.replace(/#.*$/, '&')
Mutant 8 in crawler-url-parser.js: /#.*$/ replaced with /^#.*$/
Mutant 9 in crawler-url-parser.js: /#.*$/ replaced with /#.*$/i
Mutant 10 in crawler-url-parser.js: /#.*$/ replaced with /#.*$/g
Mutant 11 in crawler-url-parser.js: '' replaced with '#'
Mutant 12 in crawler-url-parser.js: '' replaced with '#' + ' '
Mutant 13 in crawler-url-parser.js: '' replaced with '#' + '?'
Mutant 14 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*$/, ' ')
Mutant 15 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*$/, '?')
Mutant 16 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*$/, '&')
Mutant 17 in crawler-url-parser.js: /#.*$/ replaced with /^#.*$/
Mutant 18 in crawler-url-parser.js: /#.*$/ replaced with /#.*$/i
Mutant 19 in crawler-url-parser.js: /#.*$/ replaced with /#.*$/g
Mutant 20 in crawler-url-parser.js: '' replaced with '#'
Mutant 21 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with currentUrlStr.startsWith('http')
Mutant 22 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with currentUrlStr.match(/^(?!localhost)\w+:/)
Mutant 23 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, false)
Mutant 24 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 25 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
failed to parse replacement currentUrlStr.replace(/^(?!(?:\w+:)?\/\/)/, ''): SyntaxError: Invalid regular expression: //^(?!(?:\w+:)?\//: Unterminated group
Mutant 26 in crawler-url-parser.js: true replaced with false
Mutant 27 in crawler-url-parser.js: true replaced with null
Mutant 28 in crawler-url-parser.js: true replaced with undefined
Mutant 29 in crawler-url-parser.js: true replaced with false
Mutant 30 in crawler-url-parser.js: true replaced with null
Mutant 31 in crawler-url-parser.js: true replaced with undefined
Mutant 32 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' && parsedUrl.protocol != 'ftp:'
Mutant 33 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with parsedUrl.host == null
Mutant 34 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with baseUrlStr == null
Mutant 35 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with parsedUrl.host == null && baseUrlStr == null
Mutant 36 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, false, false)
Mutant 37 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, true, false)
Mutant 38 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, false, true)
Mutant 39 in crawler-url-parser.js: true replaced with false
Mutant 40 in crawler-url-parser.js: true replaced with null
Mutant 41 in crawler-url-parser.js: true replaced with undefined
Mutant 42 in crawler-url-parser.js: true replaced with false
Mutant 43 in crawler-url-parser.js: true replaced with null
Mutant 44 in crawler-url-parser.js: true replaced with undefined
Mutant 45 in crawler-url-parser.js: URL.format replaced with URL.parse
Mutant 46 in crawler-url-parser.js: URL.format replaced with URL.resolve
Mutant 47 in crawler-url-parser.js: URL.format replaced with URL.toString
Mutant 48 in crawler-url-parser.js: parsedBaseUrl replaced with parsedUrl
Mutant 49 in crawler-url-parser.js: parsedBaseUrl replaced with parsedBaseUrl.href
Mutant 50 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse(baseUrlStr)
Mutant 51 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.parse(parsedBaseUrl.resolve(parsedUrl))
Mutant 52 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.format(parsedBaseUrl.resolve(parsedUrl))
Mutant 53 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(parsedBaseUrl, parsedUrl.toString())
Mutant 54 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(parsedUrl, parsedBaseUrl)
Mutant 55 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(null, parsedUrl)
Mutant 56 in crawler-url-parser.js: URL.resolve replaced with URL.resolveObject
Mutant 57 in crawler-url-parser.js: parsedBaseUrl replaced with parsedBaseUrl.href
Mutant 58 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse(baseUrlStr)
Mutant 59 in crawler-url-parser.js: parsedUrl replaced with parsedUrl.path
Mutant 60 in crawler-url-parser.js: parsedUrl replaced with parsedUrl.host
Mutant 61 in crawler-url-parser.js: parsedUrl replaced with parsedUrl.protocol
Mutant 62 in crawler-url-parser.js: URL.format replaced with URL.parse
Mutant 63 in crawler-url-parser.js: URL.format replaced with URL.resolve
Mutant 64 in crawler-url-parser.js: URL.format replaced with URL.toString
Mutant 65 in crawler-url-parser.js: absoluteUrl replaced with URL.parse(currentUrlStr, true, false)
Mutant 66 in crawler-url-parser.js: absoluteUrl replaced with URL.parse(currentUrlStr, true, true)
Mutant 67 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, false)
Mutant 68 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 69 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 70 in crawler-url-parser.js: true replaced with false
Mutant 71 in crawler-url-parser.js: true replaced with baseUrl
Mutant 72 in crawler-url-parser.js: true replaced with false
Mutant 73 in crawler-url-parser.js: true replaced with null
Mutant 74 in crawler-url-parser.js: true replaced with undefined
Mutant 75 in crawler-url-parser.js: URL.format replaced with URL.parse
Mutant 76 in crawler-url-parser.js: URL.format replaced with URL.resolve
Mutant 77 in crawler-url-parser.js: URL.format replaced with URL.toString
Mutant 78 in crawler-url-parser.js: parsedUrl replaced with parsedUrl.href
Mutant 79 in crawler-url-parser.js: parsedUrl replaced with parsedUrl.pathname
Mutant 80 in crawler-url-parser.js: parsedUrl replaced with parsedUrl.search
Mutant 81 in crawler-url-parser.js: ret.host replaced with ret.hostname
Mutant 82 in crawler-url-parser.js: ret.host replaced with ret.host.split(':')[0]
Mutant 83 in crawler-url-parser.js: ret.host replaced with ret.host.split(':')[1]
Mutant 84 in crawler-url-parser.js: ret.host replaced with ret.hostname
Mutant 85 in crawler-url-parser.js: ret.host replaced with ret.host.split(':')[0]
Mutant 86 in crawler-url-parser.js: ret.host replaced with ret.host.split(':')[1]
Mutant 87 in crawler-url-parser.js: "=" replaced with "=="
Mutant 88 in crawler-url-parser.js: "=" replaced with "!="
Mutant 89 in crawler-url-parser.js: "=" replaced with "<>"
Mutant 90 in crawler-url-parser.js: data replaced with $('base').attr('href')
Mutant 91 in crawler-url-parser.js: data replaced with $('base').attr('href') + '/'
Mutant 92 in crawler-url-parser.js: data replaced with $('base').attr('href') + '?'
Mutant 93 in crawler-url-parser.js: 'base' replaced with 'a'
Mutant 94 in crawler-url-parser.js: 'base' replaced with '#'
Mutant 95 in crawler-url-parser.js: 'href' replaced with 'src'
Mutant 96 in crawler-url-parser.js: 'href' replaced with 'data-href'
Mutant 97 in crawler-url-parser.js: 'a' replaced with 'a[href]'
Mutant 98 in crawler-url-parser.js: this replaced with $(this).attr('href')
Mutant 99 in crawler-url-parser.js: this replaced with $(this).find('a').attr('href')
Mutant 100 in crawler-url-parser.js: this replaced with $(this).closest('a').attr('href')
Mutant 101 in crawler-url-parser.js: 'href' replaced with 'src'
Mutant 102 in crawler-url-parser.js: 'href' replaced with 'data-href'
Mutant 103 in crawler-url-parser.js: 'href' replaced with 'href' + 'src'
Mutant 104 in crawler-url-parser.js: this replaced with $(this).text()
Mutant 105 in crawler-url-parser.js: this replaced with $(this).html()
Mutant 106 in crawler-url-parser.js: this replaced with $(this).val()
Mutant 107 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with href.length < 3
Mutant 108 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with /^(javascript|mailto:|ftp:)/ig.test(href)
Mutant 109 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with typeof href == "undefined"
Mutant 110 in crawler-url-parser.js: href replaced with href.replace(/;.*$/g, "")
Mutant 111 in crawler-url-parser.js: href replaced with href.replace(/#.*$/, '')
Mutant 112 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(href, currentUrlStr)
Mutant 113 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(baseUrlStr, currentUrlStr)
Mutant 114 in crawler-url-parser.js: baseUrlStr replaced with null
Mutant 115 in crawler-url-parser.js: baseUrlStr replaced with ""
Mutant 116 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl || currentUrl.url
Mutant 117 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl && currentUrl.url != null
Mutant 118 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl && currentUrl.url !== ''
Mutant 119 in crawler-url-parser.js: urlMap.has(currentUrl.url) replaced with urlMap.has(currentUrl.url) && urlMap.get(currentUrl.url).text.includes(text)
Mutant 120 in crawler-url-parser.js: urlMap.has(currentUrl.url) replaced with urlMap.has(currentUrl.url) || urlMap.get(currentUrl.url).text.includes(text)
Mutant 121 in crawler-url-parser.js: urlMap.has(currentUrl.url) replaced with urlMap.has(currentUrl.url) && !urlMap.get(currentUrl.url).text.includes(text)
Mutant 122 in crawler-url-parser.js: urlMap.has replaced with urlMap.hasOwnProperty
Mutant 123 in crawler-url-parser.js: urlMap.has replaced with urlMap.size
Mutant 124 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.baseurl
Mutant 125 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.protocol
Mutant 126 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.host
Mutant 127 in crawler-url-parser.js: urlMap.get replaced with urlMap.set
Mutant 128 in crawler-url-parser.js: urlMap.get replaced with urlMap.clear
Mutant 129 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.baseurl
Mutant 130 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.protocol
Mutant 131 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.host
Mutant 132 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text.includes(text)
Mutant 133 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text.indexOf(text) === -1
Mutant 134 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text.lastIndexOf(text) === -1
Mutant 135 in crawler-url-parser.js: text replaced with text.toLowerCase()
Mutant 136 in crawler-url-parser.js: text replaced with text.toUpperCase()
Mutant 137 in crawler-url-parser.js: text replaced with text.split(' ').join('')
Mutant 138 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(currentUrl.url, currentUrl.url)
Mutant 139 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(currentUrl.url, currentUrl.host)
Mutant 140 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(currentUrl.url, currentUrl.path)
Mutant 141 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.baseurl
Mutant 142 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.protocol
Mutant 143 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.host
Mutant 144 in crawler-url-parser.js: currentUrl replaced with currentUrl.url
Mutant 145 in crawler-url-parser.js: currentUrl replaced with currentUrl.baseurl
Mutant 146 in crawler-url-parser.js: currentUrl replaced with currentUrl.protocol
Mutant 147 in crawler-url-parser.js: urlMap.values() replaced with urlMap.keys()
Mutant 148 in crawler-url-parser.js: urlMap.values() replaced with urlMap.entries()
Mutant 149 in crawler-url-parser.js: urlMap.values() replaced with urlMap.size
Mutant 150 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(currentUrl.baseurl)
Mutant 151 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(baseUrl.url)
Mutant 152 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(null)
Mutant 153 in crawler-url-parser.js: gettype replaced with "internal"
Mutant 154 in crawler-url-parser.js: gettype replaced with "external"
Mutant 155 in crawler-url-parser.js: gettype replaced with "uplevel"
Mutant 156 in crawler-url-parser.js: currentUrl replaced with currentUrl.url
Mutant 157 in crawler-url-parser.js: currentUrl replaced with currentUrl.baseurl
Mutant 158 in crawler-url-parser.js: currentUrl replaced with currentUrl.protocol
Mutant 159 in crawler-url-parser.js: baseUrl replaced with null
Mutant 160 in crawler-url-parser.js: baseUrl replaced with undefined
Mutant 161 in crawler-url-parser.js: urlMap.values() replaced with urlMap.keys()
Mutant 162 in crawler-url-parser.js: urlMap.values() replaced with urlMap.entries()
Mutant 163 in crawler-url-parser.js: urlMap.values() replaced with urlMap.size
Mutant 164 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl == "string"
Mutant 165 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl.length == 0
Mutant 166 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl.includes("string")
Mutant 167 in crawler-url-parser.js: linkurl replaced with linkurl.path
Mutant 168 in crawler-url-parser.js: linkurl replaced with linkurl.href
Mutant 169 in crawler-url-parser.js: linkurl replaced with linkurl.protocol
Mutant 170 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl == "string"
Mutant 171 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl.length == 0
Mutant 172 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl.indexOf("string") == -1
Mutant 173 in crawler-url-parser.js: pageurl replaced with pageurl.host
Mutant 174 in crawler-url-parser.js: pageurl replaced with pageurl.path
Mutant 175 in crawler-url-parser.js: pageurl replaced with pageurl.search
Mutant 176 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\.[a-z]+$/, '')
Mutant 177 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\.[a-z]+$/, ' ')
Mutant 178 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\.[a-z]+$/, '\\')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\.[a-z]+$/, '')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\.[a-z]+$/, ' ')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\.[a-z]+$/, '\\')
Mutant 179 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+$/g
Mutant 180 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+$/i
Mutant 181 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+$/m
Mutant 182 in crawler-url-parser.js: '/' replaced with '\\'
Mutant 183 in crawler-url-parser.js: '/' replaced with ''
Mutant 184 in crawler-url-parser.js: '/' replaced with ' '
Mutant 185 in crawler-url-parser.js: '/' replaced with '\\'
Mutant 186 in crawler-url-parser.js: '/' replaced with ''
Mutant 187 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\.[a-z]+$/, '')
not replacing pageurl_path.replace(/\/index\.[a-z]+$/, '/') with pageurl_path.replace(/\/index\.[a-z]+$/, '')
Mutant 188 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+$/g
Mutant 189 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+$/i
Mutant 190 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+$/m
Mutant 191 in crawler-url-parser.js: '/' replaced with '\\'
Mutant 192 in crawler-url-parser.js: '/' replaced with ''
Mutant 193 in crawler-url-parser.js: '/' replaced with ' '
Mutant 194 in crawler-url-parser.js: '/' replaced with '\\'
Mutant 195 in crawler-url-parser.js: '/' replaced with ' '
Mutant 196 in crawler-url-parser.js: '/' replaced with ''
Mutant 197 in crawler-url-parser.js: "/" replaced with "\\"
Mutant 198 in crawler-url-parser.js: "/" replaced with "\\/"
Mutant 199 in crawler-url-parser.js: "/" replaced with "\\"
Mutant 200 in crawler-url-parser.js: "/" replaced with "\\/"
Mutant 201 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with linkurl.host == pageurl.host
Mutant 202 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with linkurl.host.includes(pageurl.host)
Mutant 203 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with linkurl.host.startsWith(pageurl.host)
Mutant 204 in crawler-url-parser.js: part_count_diff == 0 replaced with part_count_diff == 1
Mutant 205 in crawler-url-parser.js: part_count_diff == 0 replaced with part_count_diff == -1
Mutant 206 in crawler-url-parser.js: part_count_diff == 0 replaced with part_count_diff != 0
failed to parse replacement linkurl_path.replace(/(\/[^\/]*)[\/]?$/, " "): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement linkurl_path.replace(/(\/[^\/]*)[\/]?$/, "\\"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement linkurl_path.replace(/(\/[^\/]*)[\/]?$/, "\\\\"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /(\/[^\/]*)[\/]?$/g: SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /(\/[^\/]*)[\/]?$/i: SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /(\/[^\/]*)[\/]?$/m: SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 207 in crawler-url-parser.js: "" replaced with "/"
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, " "): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "\\"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "\\\\"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /(\/[^\/]*)[\/]?$/g: SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /(\/[^\/]*)[\/]?$/i: SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /(\/[^\/]*)[\/]?$/m: SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 208 in crawler-url-parser.js: "" replaced with "/"
Mutant 209 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part === pageurl_without_last_part
Mutant 210 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part !== pageurl_without_last_part
Mutant 211 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff > 1
Mutant 212 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff < 1
Mutant 213 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff == 0
Mutant 214 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with linkurl_path.startsWith(pageurl_path)
Mutant 215 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with linkurl_path.endsWith(pageurl_path)
Mutant 216 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with linkurl_path.indexOf(pageurl_path) === 0
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 217 in crawler-url-parser.js: pageurl_path replaced with pageurl_path.split("/").pop()
Mutant 218 in crawler-url-parser.js: pageurl_path replaced with pageurl_path.substring(pageurl_path.lastIndexOf("/") + 1)
Mutant 219 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff == 0
Mutant 220 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff == -2
Mutant 221 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff == 1
Mutant 222 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.includes(pageurl_path)
Mutant 223 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.startsWith(pageurl_path)
Mutant 224 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.endsWith(pageurl_path)
Mutant 225 in crawler-url-parser.js: pageurl_path.includes replaced with pageurl_path.startsWith
Mutant 226 in crawler-url-parser.js: pageurl_path.includes replaced with pageurl_path.endsWith
Mutant 227 in crawler-url-parser.js: pageurl_path.includes replaced with pageurl_path.indexOf
failed to parse replacement linkurl_path.replace(/(\/[^\/]*)[\/]?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 228 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain != pageurl.domain
Mutant 229 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain.includes(pageurl.domain)
Mutant 230 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain.startsWith(pageurl.domain)
Mutant 231 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl_subdomain_len > pageurl_subdomain_len
Mutant 232 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl_subdomain_len == pageurl_subdomain_len
Mutant 233 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl_subdomain_len != pageurl_subdomain_len
Mutant 234 in crawler-url-parser.js: !module.parent replaced with module.parent
Mutant 235 in crawler-url-parser.js: !module.parent replaced with module.children
Mutant 236 in crawler-url-parser.js: !module.parent replaced with module.exports
Mutant 237 in crawler-url-parser.js: console.log replaced with console.error
Mutant 238 in crawler-url-parser.js: console.log replaced with console.warn
Mutant 239 in crawler-url-parser.js: console.log replaced with console.info
Mutant 240 in crawler-url-parser.js: parse replaced with "parse"
Mutant 241 in crawler-url-parser.js: parse replaced with "extract"
Mutant 242 in crawler-url-parser.js: parse replaced with "gettype"
Mutant 243 in crawler-url-parser.js: url replaced with url.replace("https", "http")
Mutant 244 in crawler-url-parser.js: url replaced with url.replace("www.", "")
Mutant 245 in crawler-url-parser.js: url replaced with url.replace("electron-window-manager", "electron-window-manager-buggy")
[32m06:17:52 (2494) INFO Instrumenter[39m Instrumented 1 source file(s) with 246 mutant(s)
[33m06:17:52 (2494) WARN DisableTypeChecksPreprocessor[39m Unable to disable type checking for file "/home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html". Shouldn't type checking be disabled for this file? Consider configuring a more restrictive "disableTypeChecks" settings (or turn it completely off with `false`) ParseError: Parse error in /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html (73:43) Opening tag "a" not terminated.
    at ngHtmlParser (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:28:15)
    at async parse (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:11:18)
    at async DisableTypeChecksPreprocessor.disableTypeChecks [as impl] (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/disable-type-checks.js:28:17)
    at async file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:27:41
    at async Promise.all (index 736)
    at async DisableTypeChecksPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:24:9)
    at async MultiPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/multi-preprocessor.js:8:13)
    at async MutantInstrumenterExecutor.execute (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/process/2-mutant-instrumenter-executor.js:30:9)
    at async Stryker.runMutationTest (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/stryker.js:33:48)
[33m06:17:52 (2494) WARN DisableTypeChecksPreprocessor[39m (disable "warnings.preprocessorErrors" to ignore this warning
[32m06:17:52 (2494) INFO ConcurrencyTokenProvider[39m Creating 1 test runner process(es).
[32m06:17:53 (2494) INFO BroadcastReporter[39m Detected that current console does not support the "progress" reporter, downgrading to "progress-append-only" reporter
[32m06:17:53 (2494) INFO DryRunExecutor[39m Starting initial test run (command test runner with "perTest" coverage analysis). This may take a while.
[32m06:17:58 (2494) INFO DryRunExecutor[39m Initial test run succeeded. Ran 1 tests in 5 seconds (net 5211 ms, overhead 1 ms).
Mutation testing 1% (elapsed: <1m, remaining: ~13m) 3/246 tested (2 survived, 0 timed out)
Mutation testing 2% (elapsed: <1m, remaining: ~13m) 6/246 tested (4 survived, 0 timed out)
Mutation testing 3% (elapsed: <1m, remaining: ~13m) 9/246 tested (5 survived, 0 timed out)
Mutation testing 4% (elapsed: <1m, remaining: ~13m) 12/246 tested (8 survived, 0 timed out)
Mutation testing 6% (elapsed: <1m, remaining: ~11m) 16/246 tested (12 survived, 0 timed out)
Mutation testing 7% (elapsed: ~1m, remaining: ~11m) 19/246 tested (15 survived, 0 timed out)
Mutation testing 8% (elapsed: ~1m, remaining: ~11m) 22/246 tested (17 survived, 0 timed out)
Mutation testing 10% (elapsed: ~1m, remaining: ~11m) 25/246 tested (19 survived, 0 timed out)
Mutation testing 11% (elapsed: ~1m, remaining: ~11m) 29/246 tested (23 survived, 0 timed out)
Mutation testing 13% (elapsed: ~1m, remaining: ~11m) 32/246 tested (26 survived, 0 timed out)
Mutation testing 14% (elapsed: ~1m, remaining: ~11m) 35/246 tested (26 survived, 0 timed out)
Mutation testing 15% (elapsed: ~2m, remaining: ~10m) 39/246 tested (29 survived, 0 timed out)
Mutation testing 17% (elapsed: ~2m, remaining: ~10m) 42/246 tested (32 survived, 0 timed out)
Mutation testing 18% (elapsed: ~2m, remaining: ~10m) 45/246 tested (35 survived, 0 timed out)
Mutation testing 19% (elapsed: ~2m, remaining: ~10m) 48/246 tested (35 survived, 0 timed out)
Mutation testing 20% (elapsed: ~2m, remaining: ~10m) 51/246 tested (37 survived, 0 timed out)
Mutation testing 22% (elapsed: ~2m, remaining: ~9m) 55/246 tested (39 survived, 0 timed out)
Mutation testing 23% (elapsed: ~3m, remaining: ~9m) 58/246 tested (41 survived, 0 timed out)
Mutation testing 25% (elapsed: ~3m, remaining: ~9m) 62/246 tested (42 survived, 0 timed out)
Mutation testing 26% (elapsed: ~3m, remaining: ~9m) 66/246 tested (43 survived, 0 timed out)
Mutation testing 28% (elapsed: ~3m, remaining: ~8m) 69/246 tested (45 survived, 0 timed out)
Mutation testing 29% (elapsed: ~3m, remaining: ~8m) 72/246 tested (47 survived, 0 timed out)
Mutation testing 30% (elapsed: ~3m, remaining: ~8m) 76/246 tested (50 survived, 0 timed out)
Mutation testing 32% (elapsed: ~4m, remaining: ~8m) 80/246 tested (51 survived, 0 timed out)
Mutation testing 33% (elapsed: ~4m, remaining: ~8m) 83/246 tested (51 survived, 0 timed out)
Mutation testing 35% (elapsed: ~4m, remaining: ~7m) 87/246 tested (52 survived, 0 timed out)
Mutation testing 36% (elapsed: ~4m, remaining: ~7m) 90/246 tested (52 survived, 0 timed out)
Mutation testing 38% (elapsed: ~4m, remaining: ~7m) 95/246 tested (52 survived, 0 timed out)
Mutation testing 39% (elapsed: ~4m, remaining: ~7m) 98/246 tested (53 survived, 0 timed out)
Mutation testing 41% (elapsed: ~5m, remaining: ~7m) 102/246 tested (53 survived, 0 timed out)
Mutation testing 43% (elapsed: ~5m, remaining: ~6m) 106/246 tested (53 survived, 0 timed out)
Mutation testing 44% (elapsed: ~5m, remaining: ~6m) 109/246 tested (56 survived, 0 timed out)
Mutation testing 45% (elapsed: ~5m, remaining: ~6m) 112/246 tested (59 survived, 0 timed out)
Mutation testing 47% (elapsed: ~5m, remaining: ~6m) 116/246 tested (59 survived, 0 timed out)
Mutation testing 48% (elapsed: ~5m, remaining: ~6m) 119/246 tested (61 survived, 0 timed out)
Mutation testing 50% (elapsed: ~6m, remaining: ~6m) 123/246 tested (64 survived, 0 timed out)
Mutation testing 51% (elapsed: ~6m, remaining: ~5m) 126/246 tested (65 survived, 0 timed out)
Mutation testing 52% (elapsed: ~6m, remaining: ~5m) 130/246 tested (66 survived, 0 timed out)
Mutation testing 54% (elapsed: ~6m, remaining: ~5m) 134/246 tested (68 survived, 0 timed out)
Mutation testing 55% (elapsed: ~6m, remaining: ~5m) 137/246 tested (71 survived, 0 timed out)
Mutation testing 57% (elapsed: ~6m, remaining: ~5m) 141/246 tested (72 survived, 0 timed out)
Mutation testing 58% (elapsed: ~7m, remaining: ~4m) 144/246 tested (72 survived, 0 timed out)
Mutation testing 60% (elapsed: ~7m, remaining: ~4m) 148/246 tested (72 survived, 0 timed out)
Mutation testing 61% (elapsed: ~7m, remaining: ~4m) 151/246 tested (72 survived, 0 timed out)
Mutation testing 62% (elapsed: ~7m, remaining: ~4m) 154/246 tested (72 survived, 0 timed out)
Mutation testing 63% (elapsed: ~7m, remaining: ~4m) 157/246 tested (73 survived, 0 timed out)
Mutation testing 65% (elapsed: ~7m, remaining: ~4m) 161/246 tested (73 survived, 0 timed out)
Mutation testing 66% (elapsed: ~8m, remaining: ~4m) 164/246 tested (73 survived, 0 timed out)
Mutation testing 67% (elapsed: ~8m, remaining: ~3m) 167/246 tested (73 survived, 0 timed out)
Mutation testing 69% (elapsed: ~8m, remaining: ~3m) 170/246 tested (73 survived, 0 timed out)
Mutation testing 70% (elapsed: ~8m, remaining: ~3m) 174/246 tested (73 survived, 0 timed out)
Mutation testing 71% (elapsed: ~8m, remaining: ~3m) 177/246 tested (74 survived, 0 timed out)
Mutation testing 73% (elapsed: ~8m, remaining: ~3m) 180/246 tested (75 survived, 0 timed out)
Mutation testing 74% (elapsed: ~9m, remaining: ~3m) 183/246 tested (77 survived, 0 timed out)
Mutation testing 76% (elapsed: ~9m, remaining: ~2m) 187/246 tested (80 survived, 0 timed out)
Mutation testing 77% (elapsed: ~9m, remaining: ~2m) 190/246 tested (83 survived, 0 timed out)
Mutation testing 78% (elapsed: ~9m, remaining: ~2m) 193/246 tested (86 survived, 0 timed out)
Mutation testing 79% (elapsed: ~9m, remaining: ~2m) 196/246 tested (89 survived, 0 timed out)
Mutation testing 81% (elapsed: ~9m, remaining: ~2m) 200/246 tested (90 survived, 0 timed out)
Mutation testing 82% (elapsed: ~10m, remaining: ~2m) 203/246 tested (91 survived, 0 timed out)
Mutation testing 83% (elapsed: ~10m, remaining: ~1m) 206/246 tested (92 survived, 0 timed out)
Mutation testing 84% (elapsed: ~10m, remaining: ~1m) 209/246 tested (92 survived, 0 timed out)
Mutation testing 86% (elapsed: ~10m, remaining: ~1m) 213/246 tested (93 survived, 0 timed out)
Mutation testing 87% (elapsed: ~10m, remaining: ~1m) 216/246 tested (94 survived, 0 timed out)
Mutation testing 89% (elapsed: ~10m, remaining: ~1m) 219/246 tested (97 survived, 0 timed out)
Mutation testing 90% (elapsed: ~11m, remaining: ~1m) 222/246 tested (97 survived, 0 timed out)
Mutation testing 91% (elapsed: ~11m, remaining: ~1m) 225/246 tested (97 survived, 0 timed out)
Mutation testing 92% (elapsed: ~11m, remaining: <1m) 228/246 tested (98 survived, 0 timed out)
Mutation testing 94% (elapsed: ~11m, remaining: <1m) 232/246 tested (100 survived, 0 timed out)
Mutation testing 95% (elapsed: ~11m, remaining: <1m) 235/246 tested (101 survived, 0 timed out)
Mutation testing 96% (elapsed: ~11m, remaining: <1m) 238/246 tested (104 survived, 0 timed out)
Mutation testing 97% (elapsed: ~12m, remaining: <1m) 241/246 tested (107 survived, 0 timed out)
Mutation testing 99% (elapsed: ~12m, remaining: <1m) 245/246 tested (111 survived, 0 timed out)

All tests
  âœ“ All tests (killed 134)

[Survived] PrecomputedMutator
crawler-url-parser.js:31:6
-   	if (typeof currentUrlStr === 'undefined') return null;
+   	if (currentUrlStr === undefined) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:31:6
-   	if (typeof currentUrlStr === 'undefined') return null;
+   	if (currentUrlStr == null) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:6
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr) && true) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:36:18
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, ' ');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/^#.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/i, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/g, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#' + ' ');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#' + '?');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, ' ');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '?');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '&');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/^#.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/i, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/g, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '#');

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:43
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:43
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, null, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:43
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, undefined, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, null);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, undefined);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, null, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, undefined, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, null);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, undefined);

[Survived] PrecomputedMutator
crawler-url-parser.js:57:28
-   		ret.baseurl = URL.format(parsedBaseUrl);
+   		ret.baseurl = URL.format(parsedBaseUrl.href);

[Survived] PrecomputedMutator
crawler-url-parser.js:57:28
-   		ret.baseurl = URL.format(parsedBaseUrl);
+   		ret.baseurl = URL.format(URL.parse(baseUrlStr));

[Survived] PrecomputedMutator
crawler-url-parser.js:59:31
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.parse(parsedBaseUrl.resolve(parsedUrl)));

[Survived] PrecomputedMutator
crawler-url-parser.js:59:31
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.format(parsedBaseUrl.resolve(parsedUrl)));

[Survived] PrecomputedMutator
crawler-url-parser.js:59:31
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.resolveObject(parsedBaseUrl, parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:59:43
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl.href, parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:59:43
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.resolve(URL.parse(baseUrlStr), parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:60:19
-   		currentUrlStr = URL.format(absoluteUrl);
+   		currentUrlStr = URL.parse(absoluteUrl);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, null);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, undefined);

[Survived] PrecomputedMutator
crawler-url-parser.js:66:23
-   	ret.url = URL.format(parsedUrl);
+   	ret.url = URL.format(parsedUrl.href);

[Survived] PrecomputedMutator
crawler-url-parser.js:72:30
-   		let parsedHost = psl.parse(ret.host);
+   		let parsedHost = psl.parse(ret.host.split(':')[0]);

[Survived] PrecomputedMutator
crawler-url-parser.js:93:4
-   	$('a').each(function (i, el) {
+   	$('a[href]').each(function (i, el) {

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($(this).val()).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (href.length < 3) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (/^(javascript|mailto:|ftp:)/ig.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined") return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href.replace(/;.*$/g, ""))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href.replace(/#.*$/, ''))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl && currentUrl.url != null) {

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl && currentUrl.url !== '') {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:8
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.url) && urlMap.get(currentUrl.url).text.includes(text)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:8
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.url) && !urlMap.get(currentUrl.url).text.includes(text)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:8
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.hasOwnProperty(currentUrl.url)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.protocol)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.host)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text.includes(text)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text.indexOf(text) === -1) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text.lastIndexOf(text) === -1) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes(text.toLowerCase())) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes(text.toUpperCase())) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes(text.split(' ').join(''))) {

[Survived] PrecomputedMutator
crawler-url-parser.js:119:29
-   		currentUrl.type = gettype(currentUrl, baseUrl);
+   		currentUrl.type = gettype(currentUrl.url, baseUrl);

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/g, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/i, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/m, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:58
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:93
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '\\');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:93
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:17
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/g, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/i, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/m, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:58
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '\\').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:58
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:58
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, ' ').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:93
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '\\');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:93
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, ' ');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:93
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:156:6
-   	if (pageurl.host == linkurl.host) {
+   	if (linkurl.host == pageurl.host) {

[Survived] PrecomputedMutator
crawler-url-parser.js:156:6
-   	if (pageurl.host == linkurl.host) {
+   	if (linkurl.host.startsWith(pageurl.host)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part === pageurl_without_last_part) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:165:8
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.startsWith(pageurl_path)) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:8
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.indexOf(pageurl_path) === 0) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl_path.split("/").pop())) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl_path.substring(pageurl_path.lastIndexOf("/") + 1))) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:167:8
-   			if (pageurl_path.includes(linkurl_path)) return "uplevel";
+   			if (pageurl_path.startsWith(linkurl_path)) return "uplevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain.includes(pageurl.domain)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain.startsWith(pageurl.domain)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (module.parent) {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (module.children) {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (module.exports) {

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	console.error("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	console.warn("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	console.info("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:205:12
-   	let res = parse(url);
+   	let res = "parse"(url);

[Survived] PrecomputedMutator
crawler-url-parser.js:205:12
-   	let res = parse(url);
+   	let res = "extract"(url);

[Survived] PrecomputedMutator
crawler-url-parser.js:205:12
-   	let res = parse(url);
+   	let res = "gettype"(url);

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(url.replace("https", "http"));

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(url.replace("www.", ""));

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(url.replace("electron-window-manager", "electron-window-manager-buggy"));

Ran 1.00 tests per mutant on average.
-----------------------|---------|----------|-----------|------------|----------|----------|
File                   | % score | # killed | # timeout | # survived | # no cov | # errors |
-----------------------|---------|----------|-----------|------------|----------|----------|
All files              |   54.47 |      134 |         0 |        112 |        0 |        0 |
 crawler-url-parser.js |   54.47 |      134 |         0 |        112 |        0 |        0 |
-----------------------|---------|----------|-----------|------------|----------|----------|
[32m06:30:12 (2494) INFO HtmlReporter[39m Your report can be found at: file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/reports/mutation/mutation.html
[32m06:30:12 (2494) INFO MutationTestExecutor[39m Done in 12 minutes 20 seconds.

real	12m21.988s
user	9m26.113s
sys	0m46.929s
