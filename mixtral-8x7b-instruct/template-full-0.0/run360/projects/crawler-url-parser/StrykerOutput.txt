*** using precomputed mutations ***
[32m00:56:07 (2541) INFO ConfigReader[39m No config file specified. Running with command line arguments.
[32m00:56:07 (2541) INFO ConfigReader[39m Use `stryker init` command to generate your config file.
[33m00:56:07 (2541) WARN PluginLoader[39m Error during loading "@stryker-mutator/karma-runner" plugin:
  Cannot find module 'karma'
Require stack:
- /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/util/dist/src/require-resolve.js
[33m00:56:07 (2541) WARN OptionsValidator[39m Unknown stryker config option "usePrecomputed".
[33m00:56:07 (2541) WARN OptionsValidator[39m Possible causes:
     * Is it a typo on your end?
     * Did you only write this property as a comment? If so, please postfix it with "_comment".
     * You might be missing a plugin that is supposed to use it. Stryker loaded plugins from: ["@stryker-mutator/*"]
     * The plugin that is using it did not contribute explicit validation. 
     (disable "warnings.unknownOptions" to ignore this warning)
[32m00:56:07 (2541) INFO ProjectReader[39m Found 1 of 741 file(s) to be mutated.
*** using precomputed mutator ***
*** retrieving 246 mutants from MUTATION_TESTING/template-full_mixtral-8x7b-instruct_0.0/mutants.json ***
failed to parse replacement 'str'.replace(/[^a-z0-9\:\/\?\#\[\]\@\!\$\&\'\(\)\*\+\,\;\=\.\-\_\~\%]/g, ''): SyntaxError: Invalid regular expression: //[^a-z0-9\:\//: Unterminated character class
Mutant 0 in crawler-url-parser.js: str replaced with 'str'.toLowerCase()
Mutant 1 in crawler-url-parser.js: typeof currentUrlStr === 'undefined' replaced with currentUrlStr === null
Mutant 2 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr !== null && _has_illegal_chars(currentUrlStr)
Mutant 3 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr && _has_illegal_chars(currentUrlStr.toString())
Mutant 4 in crawler-url-parser.js: _has_illegal_chars replaced with currentUrlStr.length > 100
Mutant 5 in crawler-url-parser.js: _has_illegal_chars replaced with typeof currentUrlStr !== 'string'
Mutant 6 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr || ''
Mutant 7 in crawler-url-parser.js: currentUrlStr replaced with String(currentUrlStr)
Mutant 8 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with typeof baseUrlStr !== 'undefined' && _has_illegal_chars(baseUrlStr)
Mutant 9 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with baseUrlStr && _has_illegal_chars(baseUrlStr.toString())
Mutant 10 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with _has_illegal_chars(baseUrlStr || '')
Mutant 11 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 12 in crawler-url-parser.js: baseUrlStr replaced with "baseUrlStr"
Mutant 13 in crawler-url-parser.js: baseUrlStr replaced with baseUrlStr.toUpperCase()
Mutant 14 in crawler-url-parser.js: /^\/\// replaced with 'http:/'
Mutant 15 in crawler-url-parser.js: /^\/\// replaced with '^/+'
Mutant 16 in crawler-url-parser.js: currentUrlStr.replace(/#.*$/, '') replaced with currentUrlStr.replace(/#.*/, '')
Mutant 17 in crawler-url-parser.js: /#.*$/ replaced with /[#].*$/
Mutant 18 in crawler-url-parser.js: /#.*$/ replaced with /#.+$/
Mutant 19 in crawler-url-parser.js: '' replaced with '#' + Math.random()
Mutant 20 in crawler-url-parser.js: '' replaced with '#some-fragment'
Mutant 21 in crawler-url-parser.js: '' replaced with '?foo=bar'
Mutant 22 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 23 in crawler-url-parser.js: baseUrlStr replaced with null
Mutant 24 in crawler-url-parser.js: baseUrlStr replaced with URL.parse(currentUrlStr, true, true).host
Mutant 25 in crawler-url-parser.js: /^\/\// replaced with '^\\/\\/'
Mutant 26 in crawler-url-parser.js: 'http://' replaced with ' '
Mutant 27 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*/, '')
Mutant 28 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/[?].*$/, '')
Mutant 29 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*$/, '!')
Mutant 30 in crawler-url-parser.js: /#.*$/ replaced with /[#].*$/
Mutant 31 in crawler-url-parser.js: /#.*$/ replaced with /;.*$/
Mutant 32 in crawler-url-parser.js: /#.*$/ replaced with /&.*$/
Mutant 33 in crawler-url-parser.js: '' replaced with baseUrlStr.slice(0, -1)
Mutant 34 in crawler-url-parser.js: '' replaced with '#foo'
Mutant 35 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with currentUrlStr.startsWith('http')
Mutant 36 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with /^[a-z0-9]+:/.test(currentUrlStr)
failed to parse replacement /^(?!(?:[a-zA-Z0-9]+:)?\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:[a-zA-Z0-9]+:)?\//: Unterminated group
failed to parse replacement /^(?!(?:\w+):\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:\w+):\//: Unterminated group
failed to parse replacement /^(?!(?:[a-zA-Z]+):\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:[a-zA-Z]+):\//: Unterminated group
Mutant 37 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 38 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 39 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr + '', true, true)
Mutant 40 in crawler-url-parser.js: URL.parse replaced with global.URL.parse
Mutant 41 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.toLowerCase()
Mutant 42 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr + ''
Mutant 43 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr || ''
Mutant 44 in crawler-url-parser.js: true replaced with false
Mutant 45 in crawler-url-parser.js: true replaced with false
Mutant 46 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true)
Mutant 47 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with parsedUrl.protocol !== 'http:' && parsedUrl.protocol !== 'https:'
Mutant 48 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with parsedUrl.protocol && parsedUrl.protocol != 'http' && parsedUrl.protocol != 'https'
Mutant 49 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with 'http:' !== parsedUrl.protocol && 'https:' !== parsedUrl.protocol
Mutant 50 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with parsedUrl.host === null && baseUrlStr
Mutant 51 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse('', true, true)
Mutant 52 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, false, true)
Mutant 53 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr, true, false)
Mutant 54 in crawler-url-parser.js: baseUrlStr replaced with baseUrl.url
Mutant 55 in crawler-url-parser.js: baseUrlStr replaced with Math.random().toString()
Mutant 56 in crawler-url-parser.js: true replaced with false
Mutant 57 in crawler-url-parser.js: true replaced with false
Mutant 58 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, true, 2)
Mutant 59 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, false, true)
Mutant 60 in crawler-url-parser.js: parsedBaseUrl replaced with parsedBaseUrl.toString()
Mutant 61 in crawler-url-parser.js: parsedBaseUrl replaced with URL.format({
  ...parsedBaseUrl
})
Mutant 62 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with new URL(parsedUrl, parsedBaseUrl).toString()
Mutant 63 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve({})
Mutant 64 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(null)
Mutant 65 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(URL.parse(''))
Mutant 66 in crawler-url-parser.js: parsedBaseUrl replaced with {}
Mutant 67 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse('')
Mutant 68 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse(currentUrlStr)
Mutant 69 in crawler-url-parser.js: parsedUrl replaced with '..'
Mutant 70 in crawler-url-parser.js: parsedUrl replaced with './'
Mutant 71 in crawler-url-parser.js: parsedUrl replaced with '/./'
Mutant 72 in crawler-url-parser.js: URL.format replaced with null
Mutant 73 in crawler-url-parser.js: absoluteUrl replaced with parsedUrl.href
Mutant 74 in crawler-url-parser.js: absoluteUrl replaced with URL.format(absoluteUrl, result_normalize_options)
Mutant 75 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 76 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 77 in crawler-url-parser.js: URL.parse replaced with global.URL.parse
Mutant 78 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.toUpperCase()
Mutant 79 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.slice(0, -1)
Mutant 80 in crawler-url-parser.js: true replaced with false
Mutant 81 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, result_normalize_options, true)
Mutant 82 in crawler-url-parser.js: true replaced with false
Mutant 83 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true, false)
Mutant 84 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, false, true)
Mutant 85 in crawler-url-parser.js: URL.format replaced with parsedUrl.href
Mutant 86 in crawler-url-parser.js: parsedUrl replaced with Object.assign({}, parsedUrl)
Mutant 87 in crawler-url-parser.js: ret.host replaced with false
Mutant 88 in crawler-url-parser.js: ret.host replaced with null
Mutant 89 in crawler-url-parser.js: psl.parse replaced with 'localhost'
Mutant 90 in crawler-url-parser.js: psl.parse replaced with null
Mutant 91 in crawler-url-parser.js: psl.parse replaced with {
  domain: 'example.com',
  subdomain: ''
}
Mutant 92 in crawler-url-parser.js: ret.host replaced with 'example.com'
Mutant 93 in crawler-url-parser.js: ret.host replaced with null
Mutant 94 in crawler-url-parser.js: ret.host replaced with Math.random()
Mutant 95 in crawler-url-parser.js: "=" replaced with '=='
Mutant 96 in crawler-url-parser.js: "=" replaced with '!=='
Mutant 97 in crawler-url-parser.js: parse replaced with 'parse'
Mutant 98 in crawler-url-parser.js: sourceUrl replaced with null
Mutant 99 in crawler-url-parser.js: 'base' replaced with 'head'
Mutant 100 in crawler-url-parser.js: 'base' replaced with $('a').eq(0)
Mutant 101 in crawler-url-parser.js: 'base' replaced with $(this).attr('data-href')
Mutant 102 in crawler-url-parser.js: 'href' replaced with 'href' in $(this) ? $(this).attr('href') : ''
Mutant 103 in crawler-url-parser.js: 'href' replaced with $(this).attr('data-link') || $(this).attr('href')
Mutant 104 in crawler-url-parser.js: 'href' replaced with $(this).prop('href')
Mutant 105 in crawler-url-parser.js: embedBaseUrlStr replaced with 'javascript:void(0)'
Mutant 106 in crawler-url-parser.js: embedBaseUrlStr replaced with true
Mutant 107 in crawler-url-parser.js: embedBaseUrlStr replaced with $('body').html()
Mutant 108 in crawler-url-parser.js: 'a' replaced with '$("body a")'
Mutant 109 in crawler-url-parser.js: 'a' replaced with 'a[href]'
Mutant 110 in crawler-url-parser.js: 'a' replaced with 'a[target!="_blank"]'
Mutant 111 in crawler-url-parser.js: $(this).attr replaced with 'attr'
Mutant 112 in crawler-url-parser.js: this replaced with $('body')
Mutant 113 in crawler-url-parser.js: this replaced with null
Mutant 114 in crawler-url-parser.js: this replaced with document.createElement('a')
Mutant 115 in crawler-url-parser.js: 'href' replaced with 'href' in el && el['href']
Mutant 116 in crawler-url-parser.js: 'href' replaced with $(el).attr('data-href')
Mutant 117 in crawler-url-parser.js: 'href' replaced with el.getAttribute('href')
Mutant 118 in crawler-url-parser.js: this replaced with $('body')
Mutant 119 in crawler-url-parser.js: this replaced with $(this).parent()
Mutant 120 in crawler-url-parser.js: this replaced with 'some text'
Mutant 121 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with href === null || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)
Mutant 122 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with typeof href === "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/i.test(href)
Mutant 123 in crawler-url-parser.js: href replaced with ''.concat(href)
Mutant 124 in crawler-url-parser.js: href replaced with href || ''
Mutant 125 in crawler-url-parser.js: href replaced with (href || '').replace(/;.*$/g, "")
Mutant 126 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse({
  href: baseUrlStr
})
Mutant 127 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(parse('some_random_string'))
Mutant 128 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(href || baseUrlStr)
Mutant 129 in crawler-url-parser.js: parse replaced with 'bad_parse'
Mutant 130 in crawler-url-parser.js: href replaced with './'
Mutant 131 in crawler-url-parser.js: href replaced with null
Mutant 132 in crawler-url-parser.js: href replaced with 'javascript:alert("XSS")'
Mutant 133 in crawler-url-parser.js: baseUrlStr replaced with 'null'
Mutant 134 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl !== null && currentUrl.url
Mutant 135 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl && currentUrl.hasOwnProperty('url')
Mutant 136 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 137 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.toString().url
Mutant 138 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.baseurl
Mutant 139 in crawler-url-parser.js: urlMap.get replaced with urlMap.has
Mutant 140 in crawler-url-parser.js: urlMap.get replaced with urlMap.prototype.get
Mutant 141 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 142 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text === text
Mutant 143 in crawler-url-parser.js: text replaced with ''
Mutant 144 in crawler-url-parser.js: text replaced with null
Mutant 145 in crawler-url-parser.js: text replaced with $(this).text()
Mutant 146 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set('currentUrl.url, "currentUrl"')
Mutant 147 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(`currentUrl.url, ${currentUrl}`)
Mutant 148 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(currentUrl.path, currentUrl)
Mutant 149 in crawler-url-parser.js: urlMap.set replaced with urlMap.has
Mutant 150 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.toString()
Mutant 151 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 152 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.__proto__.url
Mutant 153 in crawler-url-parser.js: currentUrl replaced with null
Mutant 154 in crawler-url-parser.js: currentUrl replaced with {}
Mutant 155 in crawler-url-parser.js: baseUrlStr replaced with null
Mutant 156 in crawler-url-parser.js: urlMap.values() replaced with [...urlMap.values()]
Mutant 157 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(null)
Mutant 158 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype({})
Mutant 159 in crawler-url-parser.js: gettype replaced with 'different_function'
Mutant 160 in crawler-url-parser.js: currentUrl replaced with currentUrl.protocol == null
Mutant 161 in crawler-url-parser.js: currentUrl replaced with currentUrl.url === null
Mutant 162 in crawler-url-parser.js: currentUrl replaced with currentUrl.pathname
Mutant 163 in crawler-url-parser.js: baseUrl replaced with false
Mutant 164 in crawler-url-parser.js: baseUrl replaced with null
Mutant 165 in crawler-url-parser.js: urlMap.values() replaced with [...urlMap.values()]
Mutant 166 in crawler-url-parser.js: urlMap.values() replaced with Array.from(urlMap.keys())
Mutant 167 in crawler-url-parser.js: urlMap.values() replaced with Object.values(urlMap)
Mutant 168 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl instanceof URL
Mutant 169 in crawler-url-parser.js: linkurl replaced with {}
Mutant 170 in crawler-url-parser.js: linkurl replaced with globalThis.linkurl
Mutant 171 in crawler-url-parser.js: linkurl replaced with Math.random()
Mutant 172 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl instanceof URL
Mutant 173 in crawler-url-parser.js: pageurl replaced with {}
Mutant 174 in crawler-url-parser.js: pageurl replaced with global.pageurl
Mutant 175 in crawler-url-parser.js: pageurl replaced with this.pageurl
Mutant 176 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\..+$/, '/')
Mutant 177 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\.[a-z]+$/i, '/')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\..+$/, '/')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\.[a-z]+$/i, '/')
Mutant 178 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\..+$/
Mutant 179 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[A-Z]+$/
Mutant 180 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-zA-Z]+$/
Mutant 181 in crawler-url-parser.js: '/' replaced with './'
Mutant 182 in crawler-url-parser.js: '/' replaced with ' '
Mutant 183 in crawler-url-parser.js: '/' replaced with ''
Mutant 184 in crawler-url-parser.js: /\/default\.[a-z]+$/ replaced with /[a-z]+\.[a-z]+$/
Mutant 185 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(' ')
Mutant 186 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace('')
Mutant 187 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\..+$/, '/')
not replacing pageurl_path.replace(/\/index\.[a-z]+$/, '/') with pageurl_path.replace(/\/index\..+$/, '/')
Mutant 188 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with '/index\\.[a-z]+$'
Mutant 189 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.\w+$/
Mutant 190 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+\/*$/
Mutant 191 in crawler-url-parser.js: /\/default\.[a-z]+$/ replaced with /.*$/
Mutant 192 in crawler-url-parser.js: /\/default\.[a-z]+$/ replaced with /\/[a-z]+\.[a-z]+$/
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "X"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "") + 'Y': SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 193 in crawler-url-parser.js: '/' replaced with pageurl_path.slice(0, -1)
Mutant 194 in crawler-url-parser.js: "/" replaced with "/."
Mutant 195 in crawler-url-parser.js: pageurl_path.split replaced with pageurl.path.split
not replacing pageurl_path.split with pageurl.path.split
not replacing pageurl_path.split with pageurl.path.split
Mutant 196 in crawler-url-parser.js: "/" replaced with ""
Mutant 197 in crawler-url-parser.js: "/" replaced with new RegExp('/')
Mutant 198 in crawler-url-parser.js: "/" replaced with "/".concat(String.fromCharCode(0))
Mutant 199 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with pageurl.host === linkurl.host
Mutant 200 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with pageurl.hostname == linkurl.host
Mutant 201 in crawler-url-parser.js: part_count_diff == 0 replaced with linkurl_path === pageurl_path
failed to parse replacement linkurl_path.replace(/[^\/]*$/, ""): SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement linkurl_path.replace(/(\/[^\/]+)\/?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /[^\/]*$/: SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement /[^\/]+$/: SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
Mutant 202 in crawler-url-parser.js: /(\/[^\/]*)[\/]?$/ replaced with /.*$/
failed to parse replacement pageurl_path.replace(/[^\/]*$/, ""): SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)*$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 203 in crawler-url-parser.js: "" replaced with pageurl_path
Mutant 204 in crawler-url-parser.js: "" replaced with pageurl_path + "/"
Mutant 205 in crawler-url-parser.js: "" replaced with pageurl_path.slice(0, -1)
Mutant 206 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part === pageurl_without_last_part
Mutant 207 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part.localeCompare(pageurl_without_last_part) === 0
Mutant 208 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff > 0
Mutant 209 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with pageurl_path.startsWith(linkurl_path)
Mutant 210 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with pageurl_path.indexOf(linkurl_path) !== -1
Mutant 211 in crawler-url-parser.js: pageurl_path replaced with pageurl.path
Mutant 212 in crawler-url-parser.js: pageurl_path replaced with pageurl_path.slice(0)
Mutant 213 in crawler-url-parser.js: pageurl_path replaced with pageurl_path.toLowerCase()
Mutant 214 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff === -2
Mutant 215 in crawler-url-parser.js: part_count_diff == -1 replaced with pageurl_path.startsWith(linkurl_path)
Mutant 216 in crawler-url-parser.js: part_count_diff == -1 replaced with linkurl_subdomain_len > pageurl_subdomain_len
Mutant 217 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.startsWith(pageurl_path)
Mutant 218 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with pageurl_path.indexOf(linkurl_path) !== -1
Mutant 219 in crawler-url-parser.js: linkurl_path replaced with linkurl_path.slice(0, -1)
Mutant 220 in crawler-url-parser.js: linkurl_path replaced with pageurl_path + "/"
Mutant 221 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain === pageurl.domain
Mutant 222 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.hasOwnProperty('domain') && linkurl.domain == pageurl.domain
Mutant 223 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain.toLowerCase() == pageurl.domain.toLowerCase()
Mutant 224 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl.subdomain.length < pageurl.subdomain.length
Mutant 225 in crawler-url-parser.js: !module.parent replaced with typeof module.parent === 'undefined'
Mutant 226 in crawler-url-parser.js: !module.parent replaced with !module.exports
Mutant 227 in crawler-url-parser.js: console.log replaced with console.error
Mutant 228 in crawler-url-parser.js: console.log replaced with alert
Mutant 229 in crawler-url-parser.js: "for testing purpose" replaced with "use testing purpose"
Mutant 230 in crawler-url-parser.js: "for testing purpose" replaced with "if (!module.parent) { console.log('Testing purpose');"
Mutant 231 in crawler-url-parser.js: "for testing purpose" replaced with "if (!module.parent) { console.log('Testing purposes');"
Mutant 232 in crawler-url-parser.js: url replaced with url.toUpperCase()
Mutant 233 in crawler-url-parser.js: url replaced with null
[32m00:56:08 (2541) INFO Instrumenter[39m Instrumented 1 source file(s) with 234 mutant(s)
[33m00:56:08 (2541) WARN DisableTypeChecksPreprocessor[39m Unable to disable type checking for file "/home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html". Shouldn't type checking be disabled for this file? Consider configuring a more restrictive "disableTypeChecks" settings (or turn it completely off with `false`) ParseError: Parse error in /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html (73:43) Opening tag "a" not terminated.
    at ngHtmlParser (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:28:15)
    at async parse (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:11:18)
    at async DisableTypeChecksPreprocessor.disableTypeChecks [as impl] (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/disable-type-checks.js:28:17)
    at async file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:27:41
    at async Promise.all (index 736)
    at async DisableTypeChecksPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:24:9)
    at async MultiPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/multi-preprocessor.js:8:13)
    at async MutantInstrumenterExecutor.execute (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/process/2-mutant-instrumenter-executor.js:30:9)
    at async Stryker.runMutationTest (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/stryker.js:33:48)
[33m00:56:08 (2541) WARN DisableTypeChecksPreprocessor[39m (disable "warnings.preprocessorErrors" to ignore this warning
[32m00:56:08 (2541) INFO ConcurrencyTokenProvider[39m Creating 1 test runner process(es).
[32m00:56:09 (2541) INFO BroadcastReporter[39m Detected that current console does not support the "progress" reporter, downgrading to "progress-append-only" reporter
[32m00:56:09 (2541) INFO DryRunExecutor[39m Starting initial test run (command test runner with "perTest" coverage analysis). This may take a while.
[32m00:56:14 (2541) INFO DryRunExecutor[39m Initial test run succeeded. Ran 1 tests in 4 seconds (net 4673 ms, overhead 1 ms).
Mutation testing 1% (elapsed: <1m, remaining: ~12m) 3/234 tested (1 survived, 0 timed out)
Mutation testing 2% (elapsed: <1m, remaining: ~12m) 6/234 tested (2 survived, 0 timed out)
Mutation testing 3% (elapsed: <1m, remaining: ~12m) 9/234 tested (5 survived, 0 timed out)
Mutation testing 5% (elapsed: <1m, remaining: ~12m) 12/234 tested (7 survived, 0 timed out)
Mutation testing 6% (elapsed: <1m, remaining: ~12m) 15/234 tested (8 survived, 0 timed out)
Mutation testing 7% (elapsed: ~1m, remaining: ~12m) 18/234 tested (10 survived, 0 timed out)
Mutation testing 8% (elapsed: ~1m, remaining: ~11m) 21/234 tested (13 survived, 0 timed out)
Mutation testing 10% (elapsed: ~1m, remaining: ~11m) 24/234 tested (13 survived, 0 timed out)
Mutation testing 11% (elapsed: ~1m, remaining: ~11m) 27/234 tested (13 survived, 0 timed out)
Mutation testing 12% (elapsed: ~1m, remaining: ~11m) 30/234 tested (16 survived, 0 timed out)
Mutation testing 14% (elapsed: ~1m, remaining: ~11m) 33/234 tested (19 survived, 0 timed out)
Mutation testing 15% (elapsed: ~2m, remaining: ~11m) 36/234 tested (21 survived, 0 timed out)
Mutation testing 16% (elapsed: ~2m, remaining: ~10m) 39/234 tested (23 survived, 0 timed out)
Mutation testing 17% (elapsed: ~2m, remaining: ~10m) 42/234 tested (25 survived, 0 timed out)
Mutation testing 19% (elapsed: ~2m, remaining: ~10m) 45/234 tested (28 survived, 0 timed out)
Mutation testing 20% (elapsed: ~2m, remaining: ~10m) 49/234 tested (30 survived, 0 timed out)
Mutation testing 22% (elapsed: ~2m, remaining: ~9m) 52/234 tested (31 survived, 0 timed out)
Mutation testing 23% (elapsed: ~3m, remaining: ~9m) 55/234 tested (33 survived, 0 timed out)
Mutation testing 24% (elapsed: ~3m, remaining: ~9m) 58/234 tested (35 survived, 0 timed out)
Mutation testing 26% (elapsed: ~3m, remaining: ~9m) 61/234 tested (37 survived, 0 timed out)
Mutation testing 27% (elapsed: ~3m, remaining: ~9m) 64/234 tested (38 survived, 0 timed out)
Mutation testing 29% (elapsed: ~3m, remaining: ~8m) 68/234 tested (38 survived, 0 timed out)
Mutation testing 30% (elapsed: ~3m, remaining: ~8m) 71/234 tested (38 survived, 0 timed out)
Mutation testing 31% (elapsed: ~4m, remaining: ~8m) 74/234 tested (38 survived, 0 timed out)
Mutation testing 32% (elapsed: ~4m, remaining: ~8m) 77/234 tested (41 survived, 0 timed out)
Mutation testing 34% (elapsed: ~4m, remaining: ~8m) 80/234 tested (41 survived, 0 timed out)
Mutation testing 35% (elapsed: ~4m, remaining: ~8m) 83/234 tested (44 survived, 0 timed out)
Mutation testing 36% (elapsed: ~4m, remaining: ~8m) 86/234 tested (46 survived, 0 timed out)
Mutation testing 38% (elapsed: ~4m, remaining: ~7m) 90/234 tested (47 survived, 0 timed out)
Mutation testing 40% (elapsed: ~5m, remaining: ~7m) 94/234 tested (47 survived, 0 timed out)
Mutation testing 41% (elapsed: ~5m, remaining: ~7m) 97/234 tested (47 survived, 0 timed out)
Mutation testing 43% (elapsed: ~5m, remaining: ~7m) 101/234 tested (47 survived, 0 timed out)
Mutation testing 44% (elapsed: ~5m, remaining: ~6m) 105/234 tested (47 survived, 0 timed out)
Mutation testing 46% (elapsed: ~5m, remaining: ~6m) 108/234 tested (47 survived, 0 timed out)
Mutation testing 47% (elapsed: ~5m, remaining: ~6m) 111/234 tested (48 survived, 0 timed out)
Mutation testing 48% (elapsed: ~6m, remaining: ~6m) 114/234 tested (48 survived, 0 timed out)
Mutation testing 50% (elapsed: ~6m, remaining: ~6m) 118/234 tested (48 survived, 0 timed out)
Mutation testing 51% (elapsed: ~6m, remaining: ~6m) 120/234 tested (50 survived, 0 timed out)
Mutation testing 52% (elapsed: ~6m, remaining: ~5m) 123/234 tested (53 survived, 0 timed out)
Mutation testing 54% (elapsed: ~6m, remaining: ~5m) 127/234 tested (56 survived, 0 timed out)
Mutation testing 55% (elapsed: ~6m, remaining: ~5m) 130/234 tested (56 survived, 0 timed out)
Mutation testing 57% (elapsed: ~7m, remaining: ~5m) 134/234 tested (56 survived, 0 timed out)
Mutation testing 58% (elapsed: ~7m, remaining: ~5m) 137/234 tested (59 survived, 0 timed out)
Mutation testing 59% (elapsed: ~7m, remaining: ~4m) 140/234 tested (60 survived, 0 timed out)
Mutation testing 61% (elapsed: ~7m, remaining: ~4m) 143/234 tested (62 survived, 0 timed out)
Mutation testing 62% (elapsed: ~7m, remaining: ~4m) 146/234 tested (65 survived, 0 timed out)
Mutation testing 63% (elapsed: ~7m, remaining: ~4m) 149/234 tested (65 survived, 0 timed out)
Mutation testing 64% (elapsed: ~8m, remaining: ~4m) 152/234 tested (66 survived, 0 timed out)
Mutation testing 66% (elapsed: ~8m, remaining: ~4m) 155/234 tested (66 survived, 0 timed out)
Mutation testing 67% (elapsed: ~8m, remaining: ~4m) 158/234 tested (68 survived, 0 timed out)
Mutation testing 68% (elapsed: ~8m, remaining: ~3m) 161/234 tested (68 survived, 0 timed out)
Mutation testing 70% (elapsed: ~8m, remaining: ~3m) 164/234 tested (68 survived, 0 timed out)
Mutation testing 71% (elapsed: ~8m, remaining: ~3m) 167/234 tested (69 survived, 0 timed out)
Mutation testing 72% (elapsed: ~9m, remaining: ~3m) 170/234 tested (69 survived, 0 timed out)
Mutation testing 73% (elapsed: ~9m, remaining: ~3m) 173/234 tested (69 survived, 0 timed out)
Mutation testing 75% (elapsed: ~9m, remaining: ~3m) 176/234 tested (69 survived, 0 timed out)
Mutation testing 76% (elapsed: ~9m, remaining: ~2m) 179/234 tested (72 survived, 0 timed out)
Mutation testing 77% (elapsed: ~9m, remaining: ~2m) 182/234 tested (73 survived, 0 timed out)
Mutation testing 79% (elapsed: ~9m, remaining: ~2m) 185/234 tested (74 survived, 0 timed out)
Mutation testing 80% (elapsed: ~10m, remaining: ~2m) 188/234 tested (76 survived, 0 timed out)
Mutation testing 81% (elapsed: ~10m, remaining: ~2m) 191/234 tested (79 survived, 0 timed out)
Mutation testing 82% (elapsed: ~10m, remaining: ~2m) 194/234 tested (81 survived, 0 timed out)
Mutation testing 84% (elapsed: ~10m, remaining: ~1m) 197/234 tested (82 survived, 0 timed out)
Mutation testing 85% (elapsed: ~10m, remaining: ~1m) 200/234 tested (84 survived, 0 timed out)
Mutation testing 86% (elapsed: ~10m, remaining: ~1m) 202/234 tested (84 survived, 0 timed out)
Mutation testing 87% (elapsed: ~11m, remaining: ~1m) 205/234 tested (84 survived, 0 timed out)
Mutation testing 88% (elapsed: ~11m, remaining: ~1m) 208/234 tested (86 survived, 0 timed out)
Mutation testing 90% (elapsed: ~11m, remaining: ~1m) 211/234 tested (86 survived, 0 timed out)
Mutation testing 91% (elapsed: ~11m, remaining: ~1m) 214/234 tested (89 survived, 0 timed out)
Mutation testing 92% (elapsed: ~11m, remaining: <1m) 217/234 tested (90 survived, 0 timed out)
Mutation testing 94% (elapsed: ~11m, remaining: <1m) 220/234 tested (92 survived, 0 timed out)
Mutation testing 95% (elapsed: ~12m, remaining: <1m) 223/234 tested (94 survived, 0 timed out)
Mutation testing 96% (elapsed: ~12m, remaining: <1m) 226/234 tested (96 survived, 0 timed out)
Mutation testing 97% (elapsed: ~12m, remaining: <1m) 229/234 tested (99 survived, 0 timed out)
Mutation testing 99% (elapsed: ~12m, remaining: <1m) 232/234 tested (102 survived, 0 timed out)

All tests
  ✓ All tests (killed 130)

[Survived] PrecomputedMutator
crawler-url-parser.js:32:6
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr !== null && _has_illegal_chars(currentUrlStr)) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:6
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr.toString())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr || '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(String(currentUrlStr))) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (typeof baseUrlStr !== 'undefined' && _has_illegal_chars(baseUrlStr)) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (baseUrlStr && _has_illegal_chars(baseUrlStr.toString())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (_has_illegal_chars(baseUrlStr || '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:39
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (baseUrlStr && _has_illegal_chars(baseUrlStr.toUpperCase())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:36:18
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/[#].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.+$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#' + Math.random());

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#some-fragment');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/[?].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '!');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/[#].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/;.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/&.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, baseUrlStr.slice(0, -1));

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '#foo');

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr + '', true, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:28
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr.toLowerCase(), true, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:28
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr + '', true, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:28
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr || '', true, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:43
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:54:6
-   	if (parsedUrl.host == null && baseUrlStr) {
+   	if (parsedUrl.host === null && baseUrlStr) {

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, URL.parse(baseUrlStr, true, 2));

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, URL.parse(baseUrlStr, false, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:57:28
-   		ret.baseurl = URL.format(parsedBaseUrl);
+   		ret.baseurl = URL.format(URL.format({
+     ...parsedBaseUrl
+   }));

[Survived] PrecomputedMutator
crawler-url-parser.js:60:30
-   		currentUrlStr = URL.format(absoluteUrl);
+   		currentUrlStr = URL.format(URL.format(absoluteUrl, result_normalize_options));

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, URL.parse(currentUrlStr, result_normalize_options, true), true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true, false));

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, false, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:66:23
-   	ret.url = URL.format(parsedUrl);
+   	ret.url = URL.format(Object.assign({}, parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:93:4
-   	$('a').each(function (i, el) {
+   	$('a[href]').each(function (i, el) {

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($('body')).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($(this).parent()).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $('some text').text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (href === null || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href === "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/i.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(''.concat(href))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href || '')) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test((href || '').replace(/;.*$/g, ""))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl !== null && currentUrl.url) {

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl && currentUrl.hasOwnProperty('url')) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl['url'])) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.toString().url)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:103:29
-   				let tmpUrl = urlMap.get(currentUrl.url);
+   				let tmpUrl = urlMap.get(currentUrl['url']);

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text === text) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes('')) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes(null)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes($(this).text())) {

[Survived] PrecomputedMutator
crawler-url-parser.js:110:16
-   				urlMap.set(currentUrl.url, currentUrl);
+   				urlMap.set(currentUrl['url'], currentUrl);

[Survived] PrecomputedMutator
crawler-url-parser.js:116:16
-   	urlMap.delete(baseUrlStr);
+   	urlMap.delete(null);

[Survived] PrecomputedMutator
crawler-url-parser.js:118:25
-   	for (let currentUrl of urlMap.values()) {
+   	for (let currentUrl of [...urlMap.values()]) {

[Survived] PrecomputedMutator
crawler-url-parser.js:122:26
-   	let retArr = Array.from(urlMap.values());
+   	let retArr = Array.from([...urlMap.values()]);

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/i, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-zA-Z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:58
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:17
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(' ');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:17
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace('/index\\.[a-z]+$', '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.\w+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+\/*$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:71
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/[a-z]+\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:93
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, pageurl_path.slice(0, -1));

[Survived] PrecomputedMutator
crawler-url-parser.js:152:22
-   	let pageurl_parts = pageurl_path.split("/").filter(function (elem, index, array) {
+   	let pageurl_parts = pageurl.path.split("/").filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:152:41
-   	let pageurl_parts = pageurl_path.split("/").filter(function (elem, index, array) {
+   	let pageurl_parts = pageurl_path.split(new RegExp('/')).filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:156:6
-   	if (pageurl.host == linkurl.host) {
+   	if (pageurl.host === linkurl.host) {

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part === pageurl_without_last_part) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part.localeCompare(pageurl_without_last_part) === 0) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl.path)) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl_path.slice(0))) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl_path.toLowerCase())) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:166:14
-   		} else if (part_count_diff == -1) {
+   		} else if (pageurl_path.startsWith(linkurl_path)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:167:8
-   			if (pageurl_path.includes(linkurl_path)) return "uplevel";
+   			if (pageurl_path.indexOf(linkurl_path) !== -1) return "uplevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:167:30
-   			if (pageurl_path.includes(linkurl_path)) return "uplevel";
+   			if (pageurl_path.includes(linkurl_path.slice(0, -1))) return "uplevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain === pageurl.domain) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.hasOwnProperty('domain') && linkurl.domain == pageurl.domain) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain.toLowerCase() == pageurl.domain.toLowerCase()) {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (typeof module.parent === 'undefined') {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (!module.exports) {

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	console.error("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	alert("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("use testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("if (!module.parent) { console.log('Testing purpose');");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("if (!module.parent) { console.log('Testing purposes');");

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(url.toUpperCase());

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(null);

Ran 1.00 tests per mutant on average.
-----------------------|---------|----------|-----------|------------|----------|----------|
File                   | % score | # killed | # timeout | # survived | # no cov | # errors |
-----------------------|---------|----------|-----------|------------|----------|----------|
All files              |   55.56 |      130 |         0 |        104 |        0 |        0 |
 crawler-url-parser.js |   55.56 |      130 |         0 |        104 |        0 |        0 |
-----------------------|---------|----------|-----------|------------|----------|----------|
[32m01:08:48 (2541) INFO HtmlReporter[39m Your report can be found at: file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/reports/mutation/mutation.html
[32m01:08:48 (2541) INFO MutationTestExecutor[39m Done in 12 minutes 41 seconds.

real	12m42.882s
user	9m45.816s
sys	0m48.184s
