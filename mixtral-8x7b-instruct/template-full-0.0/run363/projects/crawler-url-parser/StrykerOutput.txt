*** using precomputed mutations ***
[32m13:44:45 (2597) INFO ConfigReader[39m No config file specified. Running with command line arguments.
[32m13:44:45 (2597) INFO ConfigReader[39m Use `stryker init` command to generate your config file.
[33m13:44:46 (2597) WARN PluginLoader[39m Error during loading "@stryker-mutator/karma-runner" plugin:
  Cannot find module 'karma'
Require stack:
- /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/util/dist/src/require-resolve.js
[33m13:44:46 (2597) WARN OptionsValidator[39m Unknown stryker config option "usePrecomputed".
[33m13:44:46 (2597) WARN OptionsValidator[39m Possible causes:
     * Is it a typo on your end?
     * Did you only write this property as a comment? If so, please postfix it with "_comment".
     * You might be missing a plugin that is supposed to use it. Stryker loaded plugins from: ["@stryker-mutator/*"]
     * The plugin that is using it did not contribute explicit validation. 
     (disable "warnings.unknownOptions" to ignore this warning)
[32m13:44:46 (2597) INFO ProjectReader[39m Found 1 of 741 file(s) to be mutated.
*** using precomputed mutator ***
*** retrieving 233 mutants from MUTATION_TESTING/template-full_mixtral-8x7b-instruct_0.0/mutants.json ***
failed to parse replacement 'str'.replace(/[^a-z0-9\:\/\?\#\[\]\@\!\$\&\'\(\)\*\+\,\;\=\.\-\_\~\%]/g, ''): SyntaxError: Invalid regular expression: //[^a-z0-9\:\//: Unterminated character class
failed to parse replacement 'str'.match(/[^a-z0-9\:\/\?\#\[\]\@\!\$\&\'\(\)\*\+\,\;\=\.\-\_\~\%]/): SyntaxError: Invalid regular expression: //[^a-z0-9\:\//: Unterminated character class
Mutant 0 in crawler-url-parser.js: str replaced with 'str'.toLowerCase()
Mutant 1 in crawler-url-parser.js: typeof currentUrlStr === 'undefined' replaced with currentUrlStr === null
Mutant 2 in crawler-url-parser.js: currentUrlStr && _has_illegal_chars(currentUrlStr) replaced with currentUrlStr !== null && _has_illegal_chars(currentUrlStr)
Mutant 3 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.toLowerCase()
Mutant 4 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr || ''
Mutant 5 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with typeof baseUrlStr !== 'undefined' && _has_illegal_chars(baseUrlStr)
Mutant 6 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with baseUrlStr && _has_illegal_chars(baseUrlStr.toString())
Mutant 7 in crawler-url-parser.js: baseUrlStr && _has_illegal_chars(baseUrlStr) replaced with _has_illegal_chars(baseUrlStr || '')
Mutant 8 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 9 in crawler-url-parser.js: baseUrlStr replaced with "baseUrlStr"
Mutant 10 in crawler-url-parser.js: baseUrlStr replaced with baseUrlStr.toUpperCase()
Mutant 11 in crawler-url-parser.js: /^\/\// replaced with 'http:/'
Mutant 12 in crawler-url-parser.js: /^\/\// replaced with '^/+'
Mutant 13 in crawler-url-parser.js: /#.*$/ replaced with /[#].*$/
Mutant 14 in crawler-url-parser.js: /#.*$/ replaced with /#.+$/
Mutant 15 in crawler-url-parser.js: /#.*$/ replaced with /[?].*$/
Mutant 16 in crawler-url-parser.js: '' replaced with '#' + Math.random()
Mutant 17 in crawler-url-parser.js: '' replaced with '#some-fragment'
Mutant 18 in crawler-url-parser.js: '' replaced with '?foo=bar'
Mutant 19 in crawler-url-parser.js: baseUrlStr replaced with false
Mutant 20 in crawler-url-parser.js: baseUrlStr replaced with null
Mutant 21 in crawler-url-parser.js: /^\/\// replaced with '^\\/\\/'
Mutant 22 in crawler-url-parser.js: 'http://' replaced with ' '
Mutant 23 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*/, '')
Mutant 24 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/[?].*$/, '')
Mutant 25 in crawler-url-parser.js: baseUrlStr.replace(/#.*$/, '') replaced with baseUrlStr.replace(/#.*$/, '!')
Mutant 26 in crawler-url-parser.js: /#.*$/ replaced with /[#].*$/
Mutant 27 in crawler-url-parser.js: /#.*$/ replaced with /;.*$/
Mutant 28 in crawler-url-parser.js: /#.*$/ replaced with /&.*$/
Mutant 29 in crawler-url-parser.js: '' replaced with baseUrlStr.slice(0, -1)
Mutant 30 in crawler-url-parser.js: '' replaced with '?'
Mutant 31 in crawler-url-parser.js: '' replaced with Math.random()
Mutant 32 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with currentUrlStr.startsWith('http')
Mutant 33 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with /^[a-z0-9]+:/.test(currentUrlStr)
failed to parse replacement /^(?!(?:[a-z0-9]+:)?\/\/)/i: SyntaxError: Invalid regular expression: //^(?!(?:[a-z0-9]+:)?\//: Unterminated group
failed to parse replacement /^(?!(?:\w+):?\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:\w+):?\//: Unterminated group
failed to parse replacement /^(?!(?:https?|ftp):?\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:https?|ftp):?\//: Unterminated group
Mutant 34 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 35 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 36 in crawler-url-parser.js: true replaced with false
Mutant 37 in crawler-url-parser.js: true replaced with false
Mutant 38 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true)
Mutant 39 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true, false)
Mutant 40 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with parsedUrl.protocol !== 'http:' && parsedUrl.protocol !== 'https:'
Mutant 41 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with parsedUrl.host === null && baseUrlStr
Mutant 42 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(null, true, true)
Mutant 43 in crawler-url-parser.js: baseUrlStr replaced with baseUrl.url
Mutant 44 in crawler-url-parser.js: baseUrlStr replaced with Math.random().toString()
Mutant 45 in crawler-url-parser.js: true replaced with false
Mutant 46 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, true)
Mutant 47 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, true, false)
Mutant 48 in crawler-url-parser.js: true replaced with false
Mutant 49 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, true, 2)
Mutant 50 in crawler-url-parser.js: true replaced with URL.parse(baseUrlStr, false, true)
Mutant 51 in crawler-url-parser.js: parsedBaseUrl replaced with parsedBaseUrl.toString()
Mutant 52 in crawler-url-parser.js: parsedBaseUrl replaced with Object.assign({}, parsedBaseUrl)
Mutant 53 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve({})
Mutant 54 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(null)
Mutant 55 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(URL.parse(''))
Mutant 56 in crawler-url-parser.js: URL.resolve replaced with parsedBaseUrl.origin + parsedUrl.path
Mutant 57 in crawler-url-parser.js: parsedBaseUrl replaced with {}
Mutant 58 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse('')
Mutant 59 in crawler-url-parser.js: parsedBaseUrl replaced with URL.parse(currentUrlStr)
Mutant 60 in crawler-url-parser.js: parsedUrl replaced with '..'
Mutant 61 in crawler-url-parser.js: URL.format replaced with null
Mutant 62 in crawler-url-parser.js: absoluteUrl replaced with absoluteUrl.format()
Mutant 63 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, false, true)
Mutant 64 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr, true, false)
Mutant 65 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.toUpperCase()
Mutant 66 in crawler-url-parser.js: currentUrlStr replaced with currentUrlStr.slice(0, -1)
Mutant 67 in crawler-url-parser.js: true replaced with false
Mutant 68 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, result_normalize_options, true)
Mutant 69 in crawler-url-parser.js: true replaced with false
Mutant 70 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, true, false)
Mutant 71 in crawler-url-parser.js: true replaced with URL.parse(currentUrlStr, false, true)
Mutant 72 in crawler-url-parser.js: URL.format replaced with parsedUrl.href
Mutant 73 in crawler-url-parser.js: parsedUrl replaced with Object.assign({}, parsedUrl)
Mutant 74 in crawler-url-parser.js: ret.host replaced with false
Mutant 75 in crawler-url-parser.js: ret.host replaced with null
Mutant 76 in crawler-url-parser.js: psl.parse replaced with 'localhost'
Mutant 77 in crawler-url-parser.js: psl.parse replaced with null
Mutant 78 in crawler-url-parser.js: psl.parse replaced with {
  domain: 'example.com',
  subdomain: ''
}
Mutant 79 in crawler-url-parser.js: ret.host replaced with psl.parse('example.com')
Mutant 80 in crawler-url-parser.js: ret.host replaced with null
Mutant 81 in crawler-url-parser.js: "=" replaced with '=='
Mutant 82 in crawler-url-parser.js: "=" replaced with '!=='
Mutant 83 in crawler-url-parser.js: parse replaced with null
Mutant 84 in crawler-url-parser.js: parse replaced with 'notaparsefunction'
Mutant 85 in crawler-url-parser.js: sourceUrl replaced with null
Mutant 86 in crawler-url-parser.js: data replaced with cheerio.load('<html><body><a href="test"></a></body></html>')
Mutant 87 in crawler-url-parser.js: 'base' replaced with $('script')[0].attribs['src']
Mutant 88 in crawler-url-parser.js: 'base' replaced with $('a').eq(0).attr('href')
Mutant 89 in crawler-url-parser.js: 'base' replaced with $('a').find('href')
Mutant 90 in crawler-url-parser.js: 'href' replaced with 'href' in $(this) ? $(this).attr('href') : ''
Mutant 91 in crawler-url-parser.js: 'href' replaced with $(this).attr('data-link') || $(this).attr('href')
Mutant 92 in crawler-url-parser.js: 'href' replaced with $(this).prop('href')
Mutant 93 in crawler-url-parser.js: embedBaseUrlStr replaced with 'javascript:void(0)'
Mutant 94 in crawler-url-parser.js: embedBaseUrlStr replaced with true
Mutant 95 in crawler-url-parser.js: embedBaseUrlStr replaced with $('body').html()
Mutant 96 in crawler-url-parser.js: 'a' replaced with 'body a'
Mutant 97 in crawler-url-parser.js: 'a' replaced with '#some-id a'
Mutant 98 in crawler-url-parser.js: this replaced with $('body')
Mutant 99 in crawler-url-parser.js: this replaced with $('a')[i]
Mutant 100 in crawler-url-parser.js: this replaced with $('a').eq(i)
Mutant 101 in crawler-url-parser.js: 'href' replaced with 'href' in el && el['href']
Mutant 102 in crawler-url-parser.js: 'href' replaced with $(el).attr('data-href')
Mutant 103 in crawler-url-parser.js: 'href' replaced with el.getAttribute('href')
Mutant 104 in crawler-url-parser.js: $ replaced with '<div>'
Mutant 105 in crawler-url-parser.js: this replaced with $('body')
Mutant 106 in crawler-url-parser.js: this replaced with $(this).parent()
Mutant 107 in crawler-url-parser.js: this replaced with 'some text'
Mutant 108 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with href === null || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)
Mutant 109 in crawler-url-parser.js: typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href) replaced with typeof href === "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/i.test(href)
Mutant 110 in crawler-url-parser.js: href replaced with ''.concat(href)
Mutant 111 in crawler-url-parser.js: href replaced with href || ''
Mutant 112 in crawler-url-parser.js: href replaced with (href || '').replace(/;.*$/g, "")
Mutant 113 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse({
  href: baseUrlStr
})
Mutant 114 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(parse('some_random_string'))
Mutant 115 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(href || baseUrlStr)
Mutant 116 in crawler-url-parser.js: parse replaced with 'bad_parse'
Mutant 117 in crawler-url-parser.js: href replaced with './'
Mutant 118 in crawler-url-parser.js: href replaced with null
Mutant 119 in crawler-url-parser.js: href replaced with 'javascript:alert("Mutation testing!");'
Mutant 120 in crawler-url-parser.js: baseUrlStr replaced with 'null'
Mutant 121 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl !== null && currentUrl.url
Mutant 122 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with currentUrl && currentUrl.hasOwnProperty('url')
Mutant 123 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.toString()
Mutant 124 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 125 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.__proto__.url
Mutant 126 in crawler-url-parser.js: urlMap.get replaced with urlMap.has
Mutant 127 in crawler-url-parser.js: urlMap.get replaced with urlMap.prototype.get
Mutant 128 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 129 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text === text
Mutant 130 in crawler-url-parser.js: tmpUrl.text.includes replaced with ''.indexOf
Mutant 131 in crawler-url-parser.js: text replaced with ''
Mutant 132 in crawler-url-parser.js: text replaced with null
Mutant 133 in crawler-url-parser.js: text replaced with $(this).attr('title')
Mutant 134 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set('currentUrl.url, "currentUrl"')
Mutant 135 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(`currentUrl.url, ${currentUrl}`)
Mutant 136 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(currentUrl.path, currentUrl)
Mutant 137 in crawler-url-parser.js: urlMap.set replaced with urlMap.has
Mutant 138 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.toString()
Mutant 139 in crawler-url-parser.js: currentUrl.url replaced with currentUrl['url']
Mutant 140 in crawler-url-parser.js: currentUrl.url replaced with currentUrl.__proto__.url
Mutant 141 in crawler-url-parser.js: currentUrl replaced with null
Mutant 142 in crawler-url-parser.js: currentUrl replaced with {}
Mutant 143 in crawler-url-parser.js: currentUrl replaced with function () {
  return {
    url: currentUrl.url,
    text: text,
    type: 'unknown'
  };
}()
Mutant 144 in crawler-url-parser.js: baseUrlStr replaced with null
Mutant 145 in crawler-url-parser.js: urlMap.values() replaced with [...urlMap.values()]
Mutant 146 in crawler-url-parser.js: urlMap.values() replaced with Array.from(urlMap.keys())
Mutant 147 in crawler-url-parser.js: urlMap.values() replaced with Object.values(urlMap)
Mutant 148 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(null)
Mutant 149 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype({})
Mutant 150 in crawler-url-parser.js: currentUrl replaced with currentUrl.protocol == null
Mutant 151 in crawler-url-parser.js: currentUrl replaced with currentUrl.url === null
Mutant 152 in crawler-url-parser.js: currentUrl replaced with currentUrl.hasOwnProperty('url')
Mutant 153 in crawler-url-parser.js: baseUrl replaced with false
Mutant 154 in crawler-url-parser.js: baseUrl replaced with null
Mutant 155 in crawler-url-parser.js: urlMap.values() replaced with [...urlMap.values()]
Mutant 156 in crawler-url-parser.js: urlMap.values() replaced with Array.from(urlMap.keys())
Mutant 157 in crawler-url-parser.js: urlMap.values() replaced with Object.values(urlMap)
Mutant 158 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl instanceof URL
Mutant 159 in crawler-url-parser.js: typeof linkurl == "string" replaced with Object.prototype.toString.call(linkurl) === '[object URL]'
Mutant 160 in crawler-url-parser.js: linkurl replaced with {}
Mutant 161 in crawler-url-parser.js: linkurl replaced with null
Mutant 162 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl instanceof URL
Mutant 163 in crawler-url-parser.js: parse replaced with null
Mutant 164 in crawler-url-parser.js: parse replaced with {}
Mutant 165 in crawler-url-parser.js: pageurl replaced with {}
Mutant 166 in crawler-url-parser.js: pageurl replaced with global.pageurl
Mutant 167 in crawler-url-parser.js: pageurl replaced with this.pageurl
Mutant 168 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\..+$/, '/')
Mutant 169 in crawler-url-parser.js: linkurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with linkurl_path.replace(/\/index\.[a-z]+$/i, '/')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\..+$/, '/')
not replacing linkurl_path.replace(/\/index\.[a-z]+$/, '/') with linkurl_path.replace(/\/index\.[a-z]+$/i, '/')
Mutant 170 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\..+$/
Mutant 171 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[A-Z]+$/
Mutant 172 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-zA-Z]+$/
Mutant 173 in crawler-url-parser.js: '/' replaced with './'
Mutant 174 in crawler-url-parser.js: '/' replaced with ' '
Mutant 175 in crawler-url-parser.js: '/' replaced with ''
Mutant 176 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace('')
Mutant 177 in crawler-url-parser.js: pageurl_path.replace(/\/index\.[a-z]+$/, '/') replaced with pageurl_path.replace(/\/index\..+$/, '/')
not replacing pageurl_path.replace(/\/index\.[a-z]+$/, '/') with pageurl_path.replace(/\/index\..+$/, '/')
Mutant 178 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with '/index\\.[a-z]+$'
Mutant 179 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.\w+$/
Mutant 180 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with /\/index\.[a-z]+\/*$/
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "X"): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, "") + 'Y': SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 181 in crawler-url-parser.js: '/' replaced with pageurl_path.slice(0, -1)
Mutant 182 in crawler-url-parser.js: "/" replaced with "/".concat("")
Mutant 183 in crawler-url-parser.js: pageurl_path.split replaced with pageurl.path.split
not replacing pageurl_path.split with pageurl.path.split
not replacing pageurl_path.split with pageurl.path.split
Mutant 184 in crawler-url-parser.js: "/" replaced with ""
Mutant 185 in crawler-url-parser.js: "/" replaced with new RegExp('/')
Mutant 186 in crawler-url-parser.js: "/" replaced with "/".concat(String.fromCharCode(0))
Mutant 187 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with pageurl.host === linkurl.host
Mutant 188 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with pageurl.hostname == linkurl.host
Mutant 189 in crawler-url-parser.js: part_count_diff == 0 replaced with linkurl_path === pageurl_path
failed to parse replacement linkurl_path.replace(/[^\/]*$/, ""): SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement linkurl_path.replace(/(\/[^\/]+)\/?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement /[^\/]*$/: SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement /[^\/]+$/: SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
Mutant 190 in crawler-url-parser.js: /(\/[^\/]*)[\/]?$/ replaced with /.*$/
failed to parse replacement pageurl_path.replace(/[^\/]*$/, ""): SyntaxError: Invalid regular expression: //[^\//: Unterminated character class
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)*$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 191 in crawler-url-parser.js: "" replaced with pageurl_path
Mutant 192 in crawler-url-parser.js: "" replaced with pageurl_path + "/"
Mutant 193 in crawler-url-parser.js: "" replaced with pageurl_path.slice(0, -1)
Mutant 194 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part === pageurl_without_last_part
Mutant 195 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_without_last_part.localeCompare(pageurl_without_last_part) === 0
Mutant 196 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff > 0
Mutant 197 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with pageurl_path.startsWith(linkurl_path)
Mutant 198 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with pageurl_path.indexOf(linkurl_path) !== -1
Mutant 199 in crawler-url-parser.js: pageurl_path replaced with pageurl.path
Mutant 200 in crawler-url-parser.js: pageurl_path replaced with pageurl_path.slice(0)
Mutant 201 in crawler-url-parser.js: pageurl_path replaced with pageurl_path.concat()
Mutant 202 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff === -2
Mutant 203 in crawler-url-parser.js: part_count_diff == -1 replaced with pageurl_path.startsWith(linkurl_path)
Mutant 204 in crawler-url-parser.js: part_count_diff == -1 replaced with linkurl_subdomain_len > pageurl_subdomain_len
Mutant 205 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.startsWith(pageurl_path)
Mutant 206 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with pageurl_path.indexOf(linkurl_path) > -1
Mutant 207 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain === pageurl.domain
Mutant 208 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.hasOwnProperty('domain') && linkurl.domain == pageurl.domain
Mutant 209 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.domain.toLowerCase() == pageurl.domain.toLowerCase()
Mutant 210 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl.subdomain.length < pageurl.subdomain.length
Mutant 211 in crawler-url-parser.js: !module.parent replaced with typeof module.parent === 'undefined'
Mutant 212 in crawler-url-parser.js: !module.parent replaced with !module.exports
Mutant 213 in crawler-url-parser.js: console.log replaced with console.error
Mutant 214 in crawler-url-parser.js: console.log replaced with alert
Mutant 215 in crawler-url-parser.js: "for testing purpose" replaced with "use testing purpose"
Mutant 216 in crawler-url-parser.js: "for testing purpose" replaced with "if (!module.parent) { console.log('Testing purpose');"
Mutant 217 in crawler-url-parser.js: "for testing purpose" replaced with "if (!module.parent) { console.log('Testing purposes');"
Mutant 218 in crawler-url-parser.js: url replaced with url.toUpperCase()
Mutant 219 in crawler-url-parser.js: url replaced with null
[32m13:44:46 (2597) INFO Instrumenter[39m Instrumented 1 source file(s) with 220 mutant(s)
[33m13:44:46 (2597) WARN DisableTypeChecksPreprocessor[39m Unable to disable type checking for file "/home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html". Shouldn't type checking be disabled for this file? Consider configuring a more restrictive "disableTypeChecks" settings (or turn it completely off with `false`) ParseError: Parse error in /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html (73:43) Opening tag "a" not terminated.
    at ngHtmlParser (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:28:15)
    at async parse (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:11:18)
    at async DisableTypeChecksPreprocessor.disableTypeChecks [as impl] (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/disable-type-checks.js:28:17)
    at async file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:27:41
    at async Promise.all (index 736)
    at async DisableTypeChecksPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:24:9)
    at async MultiPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/multi-preprocessor.js:8:13)
    at async MutantInstrumenterExecutor.execute (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/process/2-mutant-instrumenter-executor.js:30:9)
    at async Stryker.runMutationTest (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/stryker.js:33:48)
[33m13:44:46 (2597) WARN DisableTypeChecksPreprocessor[39m (disable "warnings.preprocessorErrors" to ignore this warning
[32m13:44:46 (2597) INFO ConcurrencyTokenProvider[39m Creating 1 test runner process(es).
[32m13:44:48 (2597) INFO BroadcastReporter[39m Detected that current console does not support the "progress" reporter, downgrading to "progress-append-only" reporter
[32m13:44:48 (2597) INFO DryRunExecutor[39m Starting initial test run (command test runner with "perTest" coverage analysis). This may take a while.
[32m13:44:53 (2597) INFO DryRunExecutor[39m Initial test run succeeded. Ran 1 tests in 5 seconds (net 5774 ms, overhead 2 ms).
Mutation testing 1% (elapsed: <1m, remaining: ~12m) 3/220 tested (1 survived, 0 timed out)
Mutation testing 2% (elapsed: <1m, remaining: ~14m) 5/220 tested (3 survived, 0 timed out)
Mutation testing 3% (elapsed: <1m, remaining: ~13m) 8/220 tested (6 survived, 0 timed out)
Mutation testing 5% (elapsed: <1m, remaining: ~12m) 11/220 tested (7 survived, 0 timed out)
Mutation testing 6% (elapsed: <1m, remaining: ~12m) 14/220 tested (8 survived, 0 timed out)
Mutation testing 7% (elapsed: ~1m, remaining: ~11m) 17/220 tested (10 survived, 0 timed out)
Mutation testing 9% (elapsed: ~1m, remaining: ~11m) 20/220 tested (11 survived, 0 timed out)
Mutation testing 10% (elapsed: ~1m, remaining: ~11m) 23/220 tested (11 survived, 0 timed out)
Mutation testing 11% (elapsed: ~1m, remaining: ~11m) 26/220 tested (14 survived, 0 timed out)
Mutation testing 12% (elapsed: ~1m, remaining: ~11m) 28/220 tested (16 survived, 0 timed out)
Mutation testing 14% (elapsed: ~1m, remaining: ~11m) 31/220 tested (19 survived, 0 timed out)
Mutation testing 15% (elapsed: ~2m, remaining: ~10m) 34/220 tested (20 survived, 0 timed out)
Mutation testing 16% (elapsed: ~2m, remaining: ~10m) 37/220 tested (23 survived, 0 timed out)
Mutation testing 18% (elapsed: ~2m, remaining: ~10m) 40/220 tested (26 survived, 0 timed out)
Mutation testing 19% (elapsed: ~2m, remaining: ~10m) 43/220 tested (27 survived, 0 timed out)
Mutation testing 20% (elapsed: ~2m, remaining: ~10m) 46/220 tested (28 survived, 0 timed out)
Mutation testing 22% (elapsed: ~2m, remaining: ~9m) 49/220 tested (31 survived, 0 timed out)
Mutation testing 23% (elapsed: ~3m, remaining: ~9m) 52/220 tested (33 survived, 0 timed out)
Mutation testing 25% (elapsed: ~3m, remaining: ~9m) 56/220 tested (34 survived, 0 timed out)
Mutation testing 26% (elapsed: ~3m, remaining: ~9m) 59/220 tested (34 survived, 0 timed out)
Mutation testing 28% (elapsed: ~3m, remaining: ~8m) 62/220 tested (34 survived, 0 timed out)
Mutation testing 29% (elapsed: ~3m, remaining: ~8m) 64/220 tested (36 survived, 0 timed out)
Mutation testing 30% (elapsed: ~3m, remaining: ~8m) 67/220 tested (37 survived, 0 timed out)
Mutation testing 31% (elapsed: ~4m, remaining: ~8m) 70/220 tested (40 survived, 0 timed out)
Mutation testing 33% (elapsed: ~4m, remaining: ~8m) 73/220 tested (42 survived, 0 timed out)
Mutation testing 35% (elapsed: ~4m, remaining: ~8m) 77/220 tested (43 survived, 0 timed out)
Mutation testing 36% (elapsed: ~4m, remaining: ~7m) 81/220 tested (43 survived, 0 timed out)
Mutation testing 38% (elapsed: ~4m, remaining: ~7m) 84/220 tested (43 survived, 0 timed out)
Mutation testing 40% (elapsed: ~4m, remaining: ~7m) 88/220 tested (43 survived, 0 timed out)
Mutation testing 41% (elapsed: ~5m, remaining: ~7m) 91/220 tested (43 survived, 0 timed out)
Mutation testing 42% (elapsed: ~5m, remaining: ~6m) 94/220 tested (43 survived, 0 timed out)
Mutation testing 44% (elapsed: ~5m, remaining: ~6m) 97/220 tested (44 survived, 0 timed out)
Mutation testing 45% (elapsed: ~5m, remaining: ~6m) 100/220 tested (45 survived, 0 timed out)
Mutation testing 46% (elapsed: ~5m, remaining: ~6m) 103/220 tested (46 survived, 0 timed out)
Mutation testing 47% (elapsed: ~5m, remaining: ~6m) 105/220 tested (46 survived, 0 timed out)
Mutation testing 49% (elapsed: ~6m, remaining: ~6m) 108/220 tested (49 survived, 0 timed out)
Mutation testing 50% (elapsed: ~6m, remaining: ~6m) 111/220 tested (52 survived, 0 timed out)
Mutation testing 51% (elapsed: ~6m, remaining: ~5m) 114/220 tested (54 survived, 0 timed out)
Mutation testing 53% (elapsed: ~6m, remaining: ~5m) 117/220 tested (54 survived, 0 timed out)
Mutation testing 55% (elapsed: ~6m, remaining: ~5m) 121/220 tested (54 survived, 0 timed out)
Mutation testing 56% (elapsed: ~6m, remaining: ~5m) 124/220 tested (57 survived, 0 timed out)
Mutation testing 57% (elapsed: ~7m, remaining: ~5m) 127/220 tested (59 survived, 0 timed out)
Mutation testing 58% (elapsed: ~7m, remaining: ~5m) 129/220 tested (60 survived, 0 timed out)
Mutation testing 60% (elapsed: ~7m, remaining: ~4m) 132/220 tested (63 survived, 0 timed out)
Mutation testing 61% (elapsed: ~7m, remaining: ~4m) 135/220 tested (65 survived, 0 timed out)
Mutation testing 62% (elapsed: ~7m, remaining: ~4m) 138/220 tested (65 survived, 0 timed out)
Mutation testing 64% (elapsed: ~7m, remaining: ~4m) 141/220 tested (66 survived, 0 timed out)
Mutation testing 65% (elapsed: ~8m, remaining: ~4m) 145/220 tested (67 survived, 0 timed out)
Mutation testing 66% (elapsed: ~8m, remaining: ~4m) 147/220 tested (68 survived, 0 timed out)
Mutation testing 68% (elapsed: ~8m, remaining: ~3m) 150/220 tested (68 survived, 0 timed out)
Mutation testing 69% (elapsed: ~8m, remaining: ~3m) 153/220 tested (68 survived, 0 timed out)
Mutation testing 70% (elapsed: ~8m, remaining: ~3m) 156/220 tested (69 survived, 0 timed out)
Mutation testing 72% (elapsed: ~8m, remaining: ~3m) 159/220 tested (69 survived, 0 timed out)
Mutation testing 73% (elapsed: ~9m, remaining: ~3m) 162/220 tested (69 survived, 0 timed out)
Mutation testing 74% (elapsed: ~9m, remaining: ~3m) 164/220 tested (69 survived, 0 timed out)
Mutation testing 75% (elapsed: ~9m, remaining: ~2m) 167/220 tested (69 survived, 0 timed out)
Mutation testing 77% (elapsed: ~9m, remaining: ~2m) 170/220 tested (71 survived, 0 timed out)
Mutation testing 78% (elapsed: ~9m, remaining: ~2m) 173/220 tested (73 survived, 0 timed out)
Mutation testing 80% (elapsed: ~9m, remaining: ~2m) 176/220 tested (74 survived, 0 timed out)
Mutation testing 81% (elapsed: ~10m, remaining: ~2m) 179/220 tested (76 survived, 0 timed out)
Mutation testing 82% (elapsed: ~10m, remaining: ~2m) 182/220 tested (79 survived, 0 timed out)
Mutation testing 84% (elapsed: ~10m, remaining: ~1m) 185/220 tested (81 survived, 0 timed out)
Mutation testing 85% (elapsed: ~10m, remaining: ~1m) 188/220 tested (83 survived, 0 timed out)
Mutation testing 86% (elapsed: ~10m, remaining: ~1m) 190/220 tested (83 survived, 0 timed out)
Mutation testing 87% (elapsed: ~10m, remaining: ~1m) 193/220 tested (83 survived, 0 timed out)
Mutation testing 89% (elapsed: ~11m, remaining: ~1m) 196/220 tested (85 survived, 0 timed out)
Mutation testing 90% (elapsed: ~11m, remaining: ~1m) 199/220 tested (85 survived, 0 timed out)
Mutation testing 91% (elapsed: ~11m, remaining: ~1m) 202/220 tested (88 survived, 0 timed out)
Mutation testing 93% (elapsed: ~11m, remaining: <1m) 205/220 tested (89 survived, 0 timed out)
Mutation testing 94% (elapsed: ~11m, remaining: <1m) 208/220 tested (91 survived, 0 timed out)
Mutation testing 95% (elapsed: ~11m, remaining: <1m) 211/220 tested (93 survived, 0 timed out)
Mutation testing 97% (elapsed: ~12m, remaining: <1m) 214/220 tested (96 survived, 0 timed out)
Mutation testing 98% (elapsed: ~12m, remaining: <1m) 217/220 tested (99 survived, 0 timed out)

All tests
  âœ“ All tests (killed 118)

[Survived] PrecomputedMutator
crawler-url-parser.js:32:6
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr !== null && _has_illegal_chars(currentUrlStr)) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr.toLowerCase())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:32:42
-   	if (currentUrlStr && _has_illegal_chars(currentUrlStr)) return null;
+   	if (currentUrlStr && _has_illegal_chars(currentUrlStr || '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (typeof baseUrlStr !== 'undefined' && _has_illegal_chars(baseUrlStr)) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (baseUrlStr && _has_illegal_chars(baseUrlStr.toString())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:6
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (_has_illegal_chars(baseUrlStr || '')) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:33:39
-   	if (baseUrlStr && _has_illegal_chars(baseUrlStr)) return null;
+   	if (baseUrlStr && _has_illegal_chars(baseUrlStr.toUpperCase())) return null;

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/[#].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:40
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.+$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#' + Math.random());

[Survived] PrecomputedMutator
crawler-url-parser.js:36:48
-   	currentUrlStr = currentUrlStr.replace(/#.*$/, '');
+   	currentUrlStr = currentUrlStr.replace(/#.*$/, '#some-fragment');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/[?].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:16
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '!');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/[#].*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/;.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/&.*$/, '');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, baseUrlStr.slice(0, -1));

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, '?');

[Survived] PrecomputedMutator
crawler-url-parser.js:40:43
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace(/#.*$/, Math.random());

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:43
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true, false));

[Survived] PrecomputedMutator
crawler-url-parser.js:54:6
-   	if (parsedUrl.host == null && baseUrlStr) {
+   	if (parsedUrl.host === null && baseUrlStr) {

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, URL.parse(baseUrlStr, true), true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, URL.parse(baseUrlStr, true, false), true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, URL.parse(baseUrlStr, true, 2));

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, URL.parse(baseUrlStr, false, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:57:28
-   		ret.baseurl = URL.format(parsedBaseUrl);
+   		ret.baseurl = URL.format(Object.assign({}, parsedBaseUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:60:30
-   		currentUrlStr = URL.format(absoluteUrl);
+   		currentUrlStr = URL.format(absoluteUrl.format());

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, false, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, URL.parse(currentUrlStr, result_normalize_options, true), true);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, true, false));

[Survived] PrecomputedMutator
crawler-url-parser.js:63:45
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, true, URL.parse(currentUrlStr, false, true));

[Survived] PrecomputedMutator
crawler-url-parser.js:66:23
-   	ret.url = URL.format(parsedUrl);
+   	ret.url = URL.format(Object.assign({}, parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:93:4
-   	$('a').each(function (i, el) {
+   	$('body a').each(function (i, el) {

[Survived] PrecomputedMutator
crawler-url-parser.js:94:16
-   		let href = $(this).attr('href');
+   		let href = $($('a')[i]).attr('href');

[Survived] PrecomputedMutator
crawler-url-parser.js:94:16
-   		let href = $(this).attr('href');
+   		let href = $($('a').eq(i)).attr('href');

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($('body')).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $($(this).parent()).text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:95:16
-   		let text = $(this).text().trim();
+   		let text = $('some text').text().trim();

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (href === null || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:7
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href === "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/i.test(href)) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(''.concat(href))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href || '')) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:97:92
-   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test(href)) return;
+   		if (typeof href == "undefined" || href.length < 3 || /^(javascript|mailto:|ftp:)/ig.test((href || '').replace(/;.*$/g, ""))) return;

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl !== null && currentUrl.url) {

[Survived] PrecomputedMutator
crawler-url-parser.js:101:7
-   		if (currentUrl && currentUrl.url) {
+   		if (currentUrl && currentUrl.hasOwnProperty('url')) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.toString())) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl['url'])) {

[Survived] PrecomputedMutator
crawler-url-parser.js:102:19
-   			if (urlMap.has(currentUrl.url)) {
+   			if (urlMap.has(currentUrl.__proto__.url)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:103:29
-   				let tmpUrl = urlMap.get(currentUrl.url);
+   				let tmpUrl = urlMap.get(currentUrl['url']);

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text === text) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:10
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!''.indexOf(text)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes('')) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes(null)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:104:31
-   				if (!tmpUrl.text.includes(text)) {
+   				if (!tmpUrl.text.includes($(this).attr('title'))) {

[Survived] PrecomputedMutator
crawler-url-parser.js:110:16
-   				urlMap.set(currentUrl.url, currentUrl);
+   				urlMap.set(currentUrl['url'], currentUrl);

[Survived] PrecomputedMutator
crawler-url-parser.js:116:16
-   	urlMap.delete(baseUrlStr);
+   	urlMap.delete(null);

[Survived] PrecomputedMutator
crawler-url-parser.js:118:25
-   	for (let currentUrl of urlMap.values()) {
+   	for (let currentUrl of [...urlMap.values()]) {

[Survived] PrecomputedMutator
crawler-url-parser.js:122:26
-   	let retArr = Array.from(urlMap.values());
+   	let retArr = Array.from([...urlMap.values()]);

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:17
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/i, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:38
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-zA-Z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:58
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:17
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\..+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace('/index\\.[a-z]+$', '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.\w+$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:38
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+\/*$/, '/').replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:147:93
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, pageurl_path.slice(0, -1));

[Survived] PrecomputedMutator
crawler-url-parser.js:149:41
-   	let linkurl_parts = linkurl_path.split("/").filter(function (elem, index, array) {
+   	let linkurl_parts = linkurl_path.split("/".concat("")).filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:152:22
-   	let pageurl_parts = pageurl_path.split("/").filter(function (elem, index, array) {
+   	let pageurl_parts = pageurl.path.split("/").filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:152:41
-   	let pageurl_parts = pageurl_path.split("/").filter(function (elem, index, array) {
+   	let pageurl_parts = pageurl_path.split(new RegExp('/')).filter(function (elem, index, array) {

[Survived] PrecomputedMutator
crawler-url-parser.js:156:6
-   	if (pageurl.host == linkurl.host) {
+   	if (pageurl.host === linkurl.host) {

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part === pageurl_without_last_part) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:163:8
-   			if (linkurl_without_last_part == pageurl_without_last_part) return "samelevel"
+   			if (linkurl_without_last_part.localeCompare(pageurl_without_last_part) === 0) return "samelevel"

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl.path)) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl_path.slice(0))) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:165:30
-   			if (linkurl_path.includes(pageurl_path)) return "sublevel";
+   			if (linkurl_path.includes(pageurl_path.concat())) return "sublevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:166:14
-   		} else if (part_count_diff == -1) {
+   		} else if (pageurl_path.startsWith(linkurl_path)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:167:8
-   			if (pageurl_path.includes(linkurl_path)) return "uplevel";
+   			if (pageurl_path.indexOf(linkurl_path) > -1) return "uplevel";

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain === pageurl.domain) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.hasOwnProperty('domain') && linkurl.domain == pageurl.domain) {

[Survived] PrecomputedMutator
crawler-url-parser.js:171:13
-   	} else if (linkurl.domain == pageurl.domain) {
+   	} else if (linkurl.domain.toLowerCase() == pageurl.domain.toLowerCase()) {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (typeof module.parent === 'undefined') {

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (!module.exports) {

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	console.error("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:2
-   	console.log("for testing purpose");
+   	alert("for testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("use testing purpose");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("if (!module.parent) { console.log('Testing purpose');");

[Survived] PrecomputedMutator
crawler-url-parser.js:186:14
-   	console.log("for testing purpose");
+   	console.log("if (!module.parent) { console.log('Testing purposes');");

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(url.toUpperCase());

[Survived] PrecomputedMutator
crawler-url-parser.js:205:18
-   	let res = parse(url);
+   	let res = parse(null);

Ran 1.00 tests per mutant on average.
-----------------------|---------|----------|-----------|------------|----------|----------|
File                   | % score | # killed | # timeout | # survived | # no cov | # errors |
-----------------------|---------|----------|-----------|------------|----------|----------|
All files              |   53.64 |      118 |         0 |        102 |        0 |        0 |
 crawler-url-parser.js |   53.64 |      118 |         0 |        102 |        0 |        0 |
-----------------------|---------|----------|-----------|------------|----------|----------|
[32m13:57:12 (2597) INFO HtmlReporter[39m Your report can be found at: file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/reports/mutation/mutation.html
[32m13:57:12 (2597) INFO MutationTestExecutor[39m Done in 12 minutes 26 seconds.

real	12m28.354s
user	9m17.689s
sys	0m45.855s
