*** using precomputed mutations ***
[32m08:09:19 (2584) INFO ConfigReader[39m No config file specified. Running with command line arguments.
[32m08:09:19 (2584) INFO ConfigReader[39m Use `stryker init` command to generate your config file.
[33m08:09:19 (2584) WARN PluginLoader[39m Error during loading "@stryker-mutator/karma-runner" plugin:
  Cannot find module 'karma'
Require stack:
- /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/util/dist/src/require-resolve.js
[33m08:09:19 (2584) WARN OptionsValidator[39m Unknown stryker config option "usePrecomputed".
[33m08:09:19 (2584) WARN OptionsValidator[39m Possible causes:
     * Is it a typo on your end?
     * Did you only write this property as a comment? If so, please postfix it with "_comment".
     * You might be missing a plugin that is supposed to use it. Stryker loaded plugins from: ["@stryker-mutator/*"]
     * The plugin that is using it did not contribute explicit validation. 
     (disable "warnings.unknownOptions" to ignore this warning)
[32m08:09:19 (2584) INFO ProjectReader[39m Found 1 of 741 file(s) to be mutated.
*** using precomputed mutator ***
*** retrieving 73 mutants from MUTATION_TESTING/template-basic_codellama-34b-instruct_0.0/mutants.json ***
Mutant 0 in crawler-url-parser.js: str replaced with "hello"
Mutant 1 in crawler-url-parser.js: typeof currentUrlStr === 'undefined' replaced with true
failed to parse replacement currentUrlStr.replace(/^(?:https?:\/\/)?(?:www\.)?/i): SyntaxError: Invalid regular expression: //^(?:https?:\//: Unterminated group
failed to parse replacement /^(?:https?:\/\/)?/: SyntaxError: Invalid regular expression: //^(?:https?:\//: Unterminated group
failed to parse replacement /^(?!(?:\w+:)?\/\/)/: SyntaxError: Invalid regular expression: //^(?!(?:\w+:)?\//: Unterminated group
Mutant 2 in crawler-url-parser.js: /#.*$/ replaced with '#'
Mutant 3 in crawler-url-parser.js: !/^\.*\/|^(?!localhost)\w+:/.test(currentUrlStr) replaced with parsedUrl.protocol == null
Mutant 4 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr)
Mutant 5 in crawler-url-parser.js: true replaced with {
  href: $(this).attr('href'),
  text: $(this).text().trim()
}
Mutant 6 in crawler-url-parser.js: true replaced with {
  maxKeys: 1000
}
Mutant 7 in crawler-url-parser.js: parsedUrl.protocol && parsedUrl.protocol != 'http:' && parsedUrl.protocol != 'https:' replaced with parsedUrl.host != null
Mutant 8 in crawler-url-parser.js: parsedUrl.host == null && baseUrlStr replaced with parsedUrl.pathname.startsWith("../")
Mutant 9 in crawler-url-parser.js: URL.parse(baseUrlStr, true, true) replaced with URL.parse(baseUrlStr)
Mutant 10 in crawler-url-parser.js: true replaced with {
  protocol: parsedUrl.protocol,
  slashes: true,
  auth: parsedUrl.auth,
  host: parsedUrl.host,
  port: parsedUrl.port,
  hostname: parsedUrl.hostname,
  hash: parsedUrl.hash,
  search: parsedUrl.search,
  query: parsedUrl.query,
  pathname: parsedUrl.pathname,
  path: parsedUrl.path,
  href: parsedUrl.href
}
Mutant 11 in crawler-url-parser.js: true replaced with false
Mutant 12 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.format(parsedUrl)
Mutant 13 in crawler-url-parser.js: URL.resolve(parsedBaseUrl, parsedUrl) replaced with URL.resolve(baseUrlStr)
Mutant 14 in crawler-url-parser.js: parsedBaseUrl replaced with baseUrlStr
Mutant 15 in crawler-url-parser.js: parsedUrl replaced with currentUrlStr
Mutant 16 in crawler-url-parser.js: URL.parse(currentUrlStr, true, true) replaced with URL.parse(currentUrlStr)
Mutant 17 in crawler-url-parser.js: currentUrlStr replaced with parsedUrl
Mutant 18 in crawler-url-parser.js: true replaced with {
  search: parsedUrl.search,
  querycount: parsedUrl.search ? parsedUrl.search.split("=").length - 1 : 0
}
Mutant 19 in crawler-url-parser.js: ret.host replaced with parsedHost.subdomain
Mutant 20 in crawler-url-parser.js: ret.host replaced with parsedHost.domain
Mutant 21 in crawler-url-parser.js: parsedUrl.search.split replaced with parsedUrl.query.length
not replacing parsedUrl.search.split with parsedUrl.query.length
Mutant 22 in crawler-url-parser.js: "=" replaced with "&"
Mutant 23 in crawler-url-parser.js: parse replaced with sourceUrl
Mutant 24 in crawler-url-parser.js: data replaced with $('html')
Mutant 25 in crawler-url-parser.js: 'base' replaced with "a"
Mutant 26 in crawler-url-parser.js: 'href' replaced with "href"
Mutant 27 in crawler-url-parser.js: embedBaseUrlStr replaced with baseUrlStr
Mutant 28 in crawler-url-parser.js: 'a' replaced with a
Mutant 29 in crawler-url-parser.js: this replaced with $(this).attr('href')
Mutant 30 in crawler-url-parser.js: 'href' replaced with href
Mutant 31 in crawler-url-parser.js: this replaced with $(this).text()
Mutant 32 in crawler-url-parser.js: href replaced with linkurl.protocol
Mutant 33 in crawler-url-parser.js: parse(href, baseUrlStr) replaced with parse(currentUrl.url)
Mutant 34 in crawler-url-parser.js: currentUrl && currentUrl.url replaced with urlMap.has(currentUrl.url)
Mutant 35 in crawler-url-parser.js: urlMap.get replaced with currentUrl
Mutant 36 in crawler-url-parser.js: currentUrl.url replaced with currentUrl
Mutant 37 in crawler-url-parser.js: !tmpUrl.text.includes(text) replaced with tmpUrl.text.includes(text)
Mutant 38 in crawler-url-parser.js: text replaced with linkurl.text
Mutant 39 in crawler-url-parser.js: urlMap.set(currentUrl.url, currentUrl) replaced with urlMap.set(currentUrl.url)
Mutant 40 in crawler-url-parser.js: baseUrlStr replaced with baseUrl.url
Mutant 41 in crawler-url-parser.js: gettype(currentUrl, baseUrl) replaced with gettype(linkurl)
Mutant 42 in crawler-url-parser.js: currentUrl replaced with linkurl
Mutant 43 in crawler-url-parser.js: baseUrl replaced with pageurl
Mutant 44 in crawler-url-parser.js: typeof linkurl == "string" replaced with linkurl.url
Mutant 45 in crawler-url-parser.js: parse replaced with linkurl
Mutant 46 in crawler-url-parser.js: linkurl replaced with url
Mutant 47 in crawler-url-parser.js: typeof pageurl == "string" replaced with pageurl
Mutant 48 in crawler-url-parser.js: parse replaced with pageurl
Mutant 49 in crawler-url-parser.js: pageurl replaced with pageurl.url
Mutant 50 in crawler-url-parser.js: /\/index\.[a-z]+$/ replaced with "/"
Mutant 51 in crawler-url-parser.js: '/' replaced with ""
Mutant 52 in crawler-url-parser.js: '/' replaced with ""
Mutant 53 in crawler-url-parser.js: '/' replaced with ""
failed to parse replacement pageurl_path.replace(/(\/[^\/]*)[\/]?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 54 in crawler-url-parser.js: pageurl_path.split replaced with pageurl_parts
not replacing pageurl_path.split with pageurl_parts
not replacing pageurl_path.split with pageurl_parts
Mutant 55 in crawler-url-parser.js: pageurl.host == linkurl.host replaced with linkurl_parts.length > pageurl_parts.length
failed to parse replacement linkurl_path.replace(linkurl_path.replace(/(\/[^\/]*)[\/]?$/, "")): SyntaxError: Invalid regular expression: //(\//: Unterminated group
failed to parse replacement linkurl_path.replace(/(\/[^\/]*)[\/]?$/, ""): SyntaxError: Invalid regular expression: //(\//: Unterminated group
Mutant 56 in crawler-url-parser.js: /(\/[^\/]*)[\/]?$/ replaced with pageurl_without_last_part.replace(/\/[^\/]*$/, "")
Mutant 57 in crawler-url-parser.js: linkurl_without_last_part == pageurl_without_last_part replaced with linkurl_path.includes(pageurl_path)
Mutant 58 in crawler-url-parser.js: part_count_diff == 1 replaced with part_count_diff > 1
Mutant 59 in crawler-url-parser.js: linkurl_path.includes(pageurl_path) replaced with linkurl_parts[linkurl_parts.length - 1] === pageurl_parts[pageurl_parts.length - 1]
Mutant 60 in crawler-url-parser.js: pageurl_path replaced with linkurl_path.includes(pageurl_path)
Mutant 61 in crawler-url-parser.js: part_count_diff == -1 replaced with part_count_diff > 1
Mutant 62 in crawler-url-parser.js: pageurl_path.includes(linkurl_path) replaced with linkurl_path.includes(pageurl_path)
Mutant 63 in crawler-url-parser.js: linkurl.domain == pageurl.domain replaced with linkurl.host == pageurl.host
Mutant 64 in crawler-url-parser.js: linkurl_subdomain_len < pageurl_subdomain_len replaced with linkurl_parts.includes(pageurl_parts[pageurl_parts.length - 1])
Mutant 65 in crawler-url-parser.js: !module.parent replaced with true
Mutant 66 in crawler-url-parser.js: parse replaced with "electron-window-manager"
[32m08:09:19 (2584) INFO Instrumenter[39m Instrumented 1 source file(s) with 67 mutant(s)
[33m08:09:20 (2584) WARN DisableTypeChecksPreprocessor[39m Unable to disable type checking for file "/home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html". Shouldn't type checking be disabled for this file? Consider configuring a more restrictive "disableTypeChecks" settings (or turn it completely off with `false`) ParseError: Parse error in /home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/test/05_tubitak.html (73:43) Opening tag "a" not terminated.
    at ngHtmlParser (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:28:15)
    at async parse (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/parsers/html-parser.js:11:18)
    at async DisableTypeChecksPreprocessor.disableTypeChecks [as impl] (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/instrumenter/dist/src/disable-type-checks.js:28:17)
    at async file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:27:41
    at async Promise.all (index 736)
    at async DisableTypeChecksPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/disable-type-checks-preprocessor.js:24:9)
    at async MultiPreprocessor.preprocess (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/sandbox/multi-preprocessor.js:8:13)
    at async MutantInstrumenterExecutor.execute (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/process/2-mutant-instrumenter-executor.js:30:9)
    at async Stryker.runMutationTest (file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/node_modules/@stryker-mutator/core/dist/src/stryker.js:33:48)
[33m08:09:20 (2584) WARN DisableTypeChecksPreprocessor[39m (disable "warnings.preprocessorErrors" to ignore this warning
[32m08:09:20 (2584) INFO ConcurrencyTokenProvider[39m Creating 1 test runner process(es).
[32m08:09:21 (2584) INFO BroadcastReporter[39m Detected that current console does not support the "progress" reporter, downgrading to "progress-append-only" reporter
[32m08:09:21 (2584) INFO DryRunExecutor[39m Starting initial test run (command test runner with "perTest" coverage analysis). This may take a while.
[32m08:09:26 (2584) INFO DryRunExecutor[39m Initial test run succeeded. Ran 1 tests in 5 seconds (net 5016 ms, overhead 1 ms).
Mutation testing 4% (elapsed: <1m, remaining: ~3m) 3/67 tested (1 survived, 0 timed out)
Mutation testing 10% (elapsed: <1m, remaining: ~2m) 7/67 tested (3 survived, 0 timed out)
Mutation testing 14% (elapsed: <1m, remaining: ~2m) 10/67 tested (4 survived, 0 timed out)
Mutation testing 20% (elapsed: <1m, remaining: ~2m) 14/67 tested (6 survived, 0 timed out)
Mutation testing 25% (elapsed: <1m, remaining: ~2m) 17/67 tested (9 survived, 0 timed out)
Mutation testing 29% (elapsed: ~1m, remaining: ~2m) 20/67 tested (10 survived, 0 timed out)
Mutation testing 35% (elapsed: ~1m, remaining: ~2m) 24/67 tested (10 survived, 0 timed out)
Mutation testing 41% (elapsed: ~1m, remaining: ~1m) 28/67 tested (11 survived, 0 timed out)
Mutation testing 47% (elapsed: ~1m, remaining: ~1m) 32/67 tested (11 survived, 0 timed out)
Mutation testing 52% (elapsed: ~1m, remaining: ~1m) 35/67 tested (11 survived, 0 timed out)
Mutation testing 58% (elapsed: ~1m, remaining: ~1m) 39/67 tested (12 survived, 0 timed out)
Mutation testing 62% (elapsed: ~2m, remaining: ~1m) 42/67 tested (13 survived, 0 timed out)
Mutation testing 67% (elapsed: ~2m, remaining: ~1m) 45/67 tested (13 survived, 0 timed out)
Mutation testing 71% (elapsed: ~2m, remaining: <1m) 48/67 tested (13 survived, 0 timed out)
Mutation testing 77% (elapsed: ~2m, remaining: <1m) 52/67 tested (14 survived, 0 timed out)
Mutation testing 82% (elapsed: ~2m, remaining: <1m) 55/67 tested (16 survived, 0 timed out)
Mutation testing 86% (elapsed: ~2m, remaining: <1m) 58/67 tested (16 survived, 0 timed out)
Mutation testing 91% (elapsed: ~3m, remaining: <1m) 61/67 tested (16 survived, 0 timed out)
Mutation testing 95% (elapsed: ~3m, remaining: <1m) 64/67 tested (16 survived, 0 timed out)

All tests
  âœ“ All tests (killed 49)

[Survived] PrecomputedMutator
crawler-url-parser.js:40:35
-   		baseUrlStr = baseUrlStr.replace(/#.*$/, '');
+   		baseUrlStr = baseUrlStr.replace('#', '');

[Survived] PrecomputedMutator
crawler-url-parser.js:47:18
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr);

[Survived] PrecomputedMutator
crawler-url-parser.js:47:49
-   	let parsedUrl = URL.parse(currentUrlStr, true, true);
+   	let parsedUrl = URL.parse(currentUrlStr, true, {
+     maxKeys: 1000
+   });

[Survived] PrecomputedMutator
crawler-url-parser.js:55:23
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:45
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, {
+     protocol: parsedUrl.protocol,
+     slashes: true,
+     auth: parsedUrl.auth,
+     host: parsedUrl.host,
+     port: parsedUrl.port,
+     hostname: parsedUrl.hostname,
+     hash: parsedUrl.hash,
+     search: parsedUrl.search,
+     query: parsedUrl.query,
+     pathname: parsedUrl.pathname,
+     path: parsedUrl.path,
+     href: parsedUrl.href
+   }, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:55:51
-   		let parsedBaseUrl = URL.parse(baseUrlStr, true, true);
+   		let parsedBaseUrl = URL.parse(baseUrlStr, true, false);

[Survived] PrecomputedMutator
crawler-url-parser.js:59:43
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.resolve(baseUrlStr, parsedUrl));

[Survived] PrecomputedMutator
crawler-url-parser.js:59:58
-   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, parsedUrl));
+   		let absoluteUrl = URL.parse(URL.resolve(parsedBaseUrl, currentUrlStr));

[Survived] PrecomputedMutator
crawler-url-parser.js:63:14
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr);

[Survived] PrecomputedMutator
crawler-url-parser.js:63:39
-   	parsedUrl = URL.parse(currentUrlStr, true, true);
+   	parsedUrl = URL.parse(currentUrlStr, {
+     search: parsedUrl.search,
+     querycount: parsedUrl.search ? parsedUrl.search.split("=").length - 1 : 0
+   }, true);

[Survived] PrecomputedMutator
crawler-url-parser.js:88:39
-   	let embedBaseUrlStr = $('base').attr('href');
+   	let embedBaseUrlStr = $('base').attr("href");

[Survived] PrecomputedMutator
crawler-url-parser.js:104:9
-   				if (!tmpUrl.text.includes(text)) {
+   				if (tmpUrl.text.includes(text)) {

[Survived] PrecomputedMutator
crawler-url-parser.js:116:16
-   	urlMap.delete(baseUrlStr);
+   	urlMap.delete(baseUrl.url);

[Survived] PrecomputedMutator
crawler-url-parser.js:146:58
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, "").replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:146:93
-   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	linkurl_path = linkurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, "");

[Survived] PrecomputedMutator
crawler-url-parser.js:147:58
-   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, '/').replace(/\/default\.[a-z]+$/, '/');
+   	pageurl_path = pageurl_path.replace(/\/index\.[a-z]+$/, "").replace(/\/default\.[a-z]+$/, '/');

[Survived] PrecomputedMutator
crawler-url-parser.js:185:5
-   if (!module.parent) {
+   if (true) {

[Survived] PrecomputedMutator
crawler-url-parser.js:205:12
-   	let res = parse(url);
+   	let res = "electron-window-manager"(url);

Ran 1.00 tests per mutant on average.
-----------------------|---------|----------|-----------|------------|----------|----------|
File                   | % score | # killed | # timeout | # survived | # no cov | # errors |
-----------------------|---------|----------|-----------|------------|----------|----------|
All files              |   73.13 |       49 |         0 |         18 |        0 |        0 |
 crawler-url-parser.js |   73.13 |       49 |         0 |         18 |        0 |        0 |
-----------------------|---------|----------|-----------|------------|----------|----------|
[32m08:12:43 (2584) INFO HtmlReporter[39m Your report can be found at: file:///home/runner/work/llm-mutation-testing/llm-mutation-testing/crawler-url-parser/reports/mutation/mutation.html
[32m08:12:43 (2584) INFO MutationTestExecutor[39m Done in 3 minutes 24 seconds.

real	3m26.032s
user	2m36.869s
sys	0m13.584s
